/**
 * å£°çº¹ç‰¹å¾æå–å™¨
 * ä½¿ç”¨ Web Audio API æå– MFCC ç‰¹å¾
 * ç”¨äºè¯´è¯äººè¯†åˆ«
 */

class VoiceprintExtractor {
    constructor() {
        this.audioContext = null;
        this.sampleRate = 16000; // 16kHz æ ‡å‡†é‡‡æ ·ç‡
        this.frameSize = 512;    // å¸§å¤§å°
        this.hopSize = 256;      // è·³è·ƒå¤§å°
        this.numMFCC = 13;       // MFCC ç³»æ•°æ•°é‡
        this.numFilters = 26;    // Melæ»¤æ³¢å™¨æ•°é‡
    }

    /**
     * ä»éŸ³é¢‘æ–‡ä»¶æå–å£°çº¹ç‰¹å¾å‘é‡
     * @param {File} audioFile - éŸ³é¢‘æ–‡ä»¶
     * @returns {Promise<Object>} ç‰¹å¾å‘é‡å’Œå…ƒæ•°æ®
     */
    async extractFromFile(audioFile) {
        console.log('ğŸ¤ å¼€å§‹æå–å£°çº¹ç‰¹å¾...');
        console.log('æ–‡ä»¶ä¿¡æ¯:', {
            name: audioFile.name,
            size: (audioFile.size / 1024).toFixed(2) + 'KB',
            type: audioFile.type
        });

        try {
            // 1. åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
            if (!this.audioContext) {
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: this.sampleRate
                });
            }

            // 2. è¯»å–å¹¶è§£ç éŸ³é¢‘æ–‡ä»¶
            const arrayBuffer = await audioFile.arrayBuffer();
            const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);

            console.log('âœ… éŸ³é¢‘è§£ç æˆåŠŸ:', {
                duration: audioBuffer.duration.toFixed(2) + 's',
                sampleRate: audioBuffer.sampleRate + 'Hz',
                channels: audioBuffer.numberOfChannels
            });

            // 3. è·å–éŸ³é¢‘æ•°æ® (å•å£°é“)
            const channelData = this.getMonoChannel(audioBuffer);

            // 4. é‡é‡‡æ ·åˆ°æ ‡å‡†é‡‡æ ·ç‡ (å¦‚æœéœ€è¦)
            const resampledData = await this.resample(channelData, audioBuffer.sampleRate, this.sampleRate);

            // 5. æå– MFCC ç‰¹å¾
            const mfccFeatures = this.computeMFCC(resampledData);

            // 6. è®¡ç®—ç»Ÿè®¡ç‰¹å¾ (å‡å€¼ã€æ–¹å·®)
            const featureVector = this.computeStatistics(mfccFeatures);

            // 7. è®¡ç®—å…¶ä»–ç‰¹å¾
            const spectralFeatures = this.computeSpectralFeatures(resampledData);
            const energyFeatures = this.computeEnergyFeatures(resampledData);

            // 8. åˆå¹¶æ‰€æœ‰ç‰¹å¾
            const finalVector = [
                ...featureVector.mean,      // MFCCå‡å€¼ (13ç»´)
                ...featureVector.std,       // MFCCæ–¹å·® (13ç»´)
                ...spectralFeatures,        // é¢‘è°±ç‰¹å¾ (5ç»´)
                ...energyFeatures           // èƒ½é‡ç‰¹å¾ (3ç»´)
            ];

            console.log('âœ… ç‰¹å¾æå–å®Œæˆ!');
            console.log('ç‰¹å¾å‘é‡ç»´åº¦:', finalVector.length);

            return {
                vector: finalVector,              // ç‰¹å¾å‘é‡ (34ç»´)
                duration: audioBuffer.duration,   // éŸ³é¢‘æ—¶é•¿
                sampleRate: this.sampleRate,      // é‡‡æ ·ç‡
                mfccFrames: mfccFeatures.length,  // MFCCå¸§æ•°
                extractedAt: new Date().toISOString(),
                metadata: {
                    originalSampleRate: audioBuffer.sampleRate,
                    fileSize: audioFile.size,
                    fileType: audioFile.type,
                    fileName: audioFile.name
                }
            };

        } catch (error) {
            console.error('âŒ ç‰¹å¾æå–å¤±è´¥:', error);
            throw new Error('å£°çº¹ç‰¹å¾æå–å¤±è´¥: ' + error.message);
        }
    }

    /**
     * ä»éŸ³é¢‘æ•°æ®æå–å£°çº¹ (å®æ—¶è¯†åˆ«ç”¨)
     * @param {Float32Array} audioData - éŸ³é¢‘æ•°æ®
     * @param {number} sampleRate - é‡‡æ ·ç‡
     * @returns {Array<number>} ç‰¹å¾å‘é‡
     */
    extractFromAudioData(audioData, sampleRate = 16000) {
        try {
            // é‡é‡‡æ ·
            const resampledData = this.resampleSync(audioData, sampleRate, this.sampleRate);

            // æå–MFCC
            const mfccFeatures = this.computeMFCC(resampledData);

            // è®¡ç®—ç»Ÿè®¡ç‰¹å¾
            const stats = this.computeStatistics(mfccFeatures);

            // è¿”å›ç®€åŒ–å‘é‡ (å‡å€¼)
            return stats.mean;

        } catch (error) {
            console.error('å®æ—¶ç‰¹å¾æå–å¤±è´¥:', error);
            return null;
        }
    }

    /**
     * è·å–å•å£°é“æ•°æ®
     */
    getMonoChannel(audioBuffer) {
        if (audioBuffer.numberOfChannels === 1) {
            return audioBuffer.getChannelData(0);
        }

        // å¤šå£°é“æ··åˆä¸ºå•å£°é“
        const length = audioBuffer.length;
        const mono = new Float32Array(length);
        for (let i = 0; i < length; i++) {
            let sum = 0;
            for (let c = 0; c < audioBuffer.numberOfChannels; c++) {
                sum += audioBuffer.getChannelData(c)[i];
            }
            mono[i] = sum / audioBuffer.numberOfChannels;
        }
        return mono;
    }

    /**
     * é‡é‡‡æ · (å¼‚æ­¥)
     */
    async resample(audioData, fromSampleRate, toSampleRate) {
        if (fromSampleRate === toSampleRate) {
            return audioData;
        }

        const ratio = toSampleRate / fromSampleRate;
        const newLength = Math.round(audioData.length * ratio);
        const resampled = new Float32Array(newLength);

        for (let i = 0; i < newLength; i++) {
            const srcIndex = i / ratio;
            const index = Math.floor(srcIndex);
            const fraction = srcIndex - index;

            if (index + 1 < audioData.length) {
                // çº¿æ€§æ’å€¼
                resampled[i] = audioData[index] * (1 - fraction) + audioData[index + 1] * fraction;
            } else {
                resampled[i] = audioData[index];
            }
        }

        return resampled;
    }

    /**
     * é‡é‡‡æ · (åŒæ­¥)
     */
    resampleSync(audioData, fromSampleRate, toSampleRate) {
        if (fromSampleRate === toSampleRate) {
            return audioData;
        }

        const ratio = toSampleRate / fromSampleRate;
        const newLength = Math.round(audioData.length * ratio);
        const resampled = new Float32Array(newLength);

        for (let i = 0; i < newLength; i++) {
            const srcIndex = i / ratio;
            const index = Math.floor(srcIndex);
            resampled[i] = audioData[Math.min(index, audioData.length - 1)];
        }

        return resampled;
    }

    /**
     * è®¡ç®— MFCC ç‰¹å¾
     */
    computeMFCC(audioData) {
        const frames = this.splitFrames(audioData, this.frameSize, this.hopSize);
        const mfccFeatures = [];

        for (let frame of frames) {
            // 1. é¢„åŠ é‡
            const preemphasized = this.preemphasis(frame);

            // 2. åŠ çª— (æ±‰æ˜çª—)
            const windowed = this.applyWindow(preemphasized);

            // 3. FFT
            const spectrum = this.computeFFT(windowed);

            // 4. åŠŸç‡è°±
            const powerSpectrum = this.computePowerSpectrum(spectrum);

            // 5. Melæ»¤æ³¢å™¨ç»„
            const melSpectrum = this.applyMelFilterbank(powerSpectrum);

            // 6. å¯¹æ•°
            const logMel = melSpectrum.map(x => Math.log(Math.max(x, 1e-10)));

            // 7. DCT -> MFCC
            const mfcc = this.computeDCT(logMel, this.numMFCC);

            mfccFeatures.push(mfcc);
        }

        return mfccFeatures;
    }

    /**
     * åˆ†å¸§
     */
    splitFrames(audioData, frameSize, hopSize) {
        const frames = [];
        for (let i = 0; i + frameSize <= audioData.length; i += hopSize) {
            frames.push(audioData.slice(i, i + frameSize));
        }
        return frames;
    }

    /**
     * é¢„åŠ é‡
     */
    preemphasis(frame, alpha = 0.97) {
        const output = new Float32Array(frame.length);
        output[0] = frame[0];
        for (let i = 1; i < frame.length; i++) {
            output[i] = frame[i] - alpha * frame[i - 1];
        }
        return output;
    }

    /**
     * åº”ç”¨æ±‰æ˜çª—
     */
    applyWindow(frame) {
        const windowed = new Float32Array(frame.length);
        for (let i = 0; i < frame.length; i++) {
            windowed[i] = frame[i] * (0.54 - 0.46 * Math.cos(2 * Math.PI * i / (frame.length - 1)));
        }
        return windowed;
    }

    /**
     * FFT (ä½¿ç”¨ç®€åŒ–çš„DFTå®ç°)
     */
    computeFFT(frame) {
        const N = frame.length;
        const real = new Float32Array(N / 2 + 1);
        const imag = new Float32Array(N / 2 + 1);

        for (let k = 0; k <= N / 2; k++) {
            let sumReal = 0;
            let sumImag = 0;
            for (let n = 0; n < N; n++) {
                const angle = -2 * Math.PI * k * n / N;
                sumReal += frame[n] * Math.cos(angle);
                sumImag += frame[n] * Math.sin(angle);
            }
            real[k] = sumReal;
            imag[k] = sumImag;
        }

        return { real, imag };
    }

    /**
     * è®¡ç®—åŠŸç‡è°±
     */
    computePowerSpectrum(spectrum) {
        const power = new Float32Array(spectrum.real.length);
        for (let i = 0; i < power.length; i++) {
            power[i] = spectrum.real[i] * spectrum.real[i] + spectrum.imag[i] * spectrum.imag[i];
        }
        return power;
    }

    /**
     * Melæ»¤æ³¢å™¨ç»„
     */
    applyMelFilterbank(powerSpectrum) {
        const melFilters = this.getMelFilterbank(powerSpectrum.length, this.numFilters);
        const melSpectrum = new Float32Array(this.numFilters);

        for (let i = 0; i < this.numFilters; i++) {
            let sum = 0;
            for (let j = 0; j < powerSpectrum.length; j++) {
                sum += powerSpectrum[j] * melFilters[i][j];
            }
            melSpectrum[i] = sum;
        }

        return melSpectrum;
    }

    /**
     * ç”ŸæˆMelæ»¤æ³¢å™¨ç»„
     */
    getMelFilterbank(nfft, numFilters) {
        const lowFreq = 0;
        const highFreq = this.sampleRate / 2;

        // Hz to Mel
        const melLow = this.hzToMel(lowFreq);
        const melHigh = this.hzToMel(highFreq);

        // Mel points
        const melPoints = [];
        for (let i = 0; i < numFilters + 2; i++) {
            melPoints.push(melLow + (melHigh - melLow) * i / (numFilters + 1));
        }

        // Mel to Hz
        const hzPoints = melPoints.map(mel => this.melToHz(mel));

        // Bin points
        const binPoints = hzPoints.map(hz => Math.floor((nfft + 1) * hz / this.sampleRate));

        // Create filterbank
        const filterbank = [];
        for (let i = 1; i <= numFilters; i++) {
            const filter = new Float32Array(nfft);
            for (let j = binPoints[i - 1]; j < binPoints[i]; j++) {
                filter[j] = (j - binPoints[i - 1]) / (binPoints[i] - binPoints[i - 1]);
            }
            for (let j = binPoints[i]; j < binPoints[i + 1]; j++) {
                filter[j] = (binPoints[i + 1] - j) / (binPoints[i + 1] - binPoints[i]);
            }
            filterbank.push(filter);
        }

        return filterbank;
    }

    /**
     * Hz to Mel
     */
    hzToMel(hz) {
        return 2595 * Math.log10(1 + hz / 700);
    }

    /**
     * Mel to Hz
     */
    melToHz(mel) {
        return 700 * (Math.pow(10, mel / 2595) - 1);
    }

    /**
     * DCT (ç¦»æ•£ä½™å¼¦å˜æ¢)
     */
    computeDCT(input, numCoeffs) {
        const N = input.length;
        const output = new Float32Array(numCoeffs);

        for (let k = 0; k < numCoeffs; k++) {
            let sum = 0;
            for (let n = 0; n < N; n++) {
                sum += input[n] * Math.cos(Math.PI * k * (n + 0.5) / N);
            }
            output[k] = sum;
        }

        return output;
    }

    /**
     * è®¡ç®—ç»Ÿè®¡ç‰¹å¾
     */
    computeStatistics(mfccFeatures) {
        const numCoeffs = mfccFeatures[0].length;
        const mean = new Float32Array(numCoeffs);
        const std = new Float32Array(numCoeffs);

        // è®¡ç®—å‡å€¼
        for (let i = 0; i < numCoeffs; i++) {
            let sum = 0;
            for (let frame of mfccFeatures) {
                sum += frame[i];
            }
            mean[i] = sum / mfccFeatures.length;
        }

        // è®¡ç®—æ–¹å·®
        for (let i = 0; i < numCoeffs; i++) {
            let sumSq = 0;
            for (let frame of mfccFeatures) {
                const diff = frame[i] - mean[i];
                sumSq += diff * diff;
            }
            std[i] = Math.sqrt(sumSq / mfccFeatures.length);
        }

        return {
            mean: Array.from(mean),
            std: Array.from(std)
        };
    }

    /**
     * è®¡ç®—é¢‘è°±ç‰¹å¾
     */
    computeSpectralFeatures(audioData) {
        const spectrum = this.computeFFT(audioData);
        const powerSpectrum = this.computePowerSpectrum(spectrum);

        // 1. é¢‘è°±è´¨å¿ƒ
        let numerator = 0;
        let denominator = 0;
        for (let i = 0; i < powerSpectrum.length; i++) {
            numerator += i * powerSpectrum[i];
            denominator += powerSpectrum[i];
        }
        const spectralCentroid = numerator / Math.max(denominator, 1e-10);

        // 2. é¢‘è°±å¸¦å®½
        let bandwidthSum = 0;
        for (let i = 0; i < powerSpectrum.length; i++) {
            bandwidthSum += Math.pow(i - spectralCentroid, 2) * powerSpectrum[i];
        }
        const spectralBandwidth = Math.sqrt(bandwidthSum / Math.max(denominator, 1e-10));

        // 3. é¢‘è°±æ»šé™
        const rolloffThreshold = 0.85 * denominator;
        let rolloffSum = 0;
        let spectralRolloff = 0;
        for (let i = 0; i < powerSpectrum.length; i++) {
            rolloffSum += powerSpectrum[i];
            if (rolloffSum >= rolloffThreshold) {
                spectralRolloff = i;
                break;
            }
        }

        // 4. è¿‡é›¶ç‡
        let zeroCrossings = 0;
        for (let i = 1; i < audioData.length; i++) {
            if ((audioData[i] >= 0 && audioData[i - 1] < 0) || (audioData[i] < 0 && audioData[i - 1] >= 0)) {
                zeroCrossings++;
            }
        }
        const zeroCrossingRate = zeroCrossings / audioData.length;

        // 5. é¢‘è°±é€šé‡
        const spectralFlux = Math.sqrt(powerSpectrum.reduce((sum, val) => sum + val * val, 0));

        return [
            spectralCentroid / powerSpectrum.length,  // å½’ä¸€åŒ–
            spectralBandwidth / powerSpectrum.length,
            spectralRolloff / powerSpectrum.length,
            zeroCrossingRate,
            spectralFlux / powerSpectrum.length
        ];
    }

    /**
     * è®¡ç®—èƒ½é‡ç‰¹å¾
     */
    computeEnergyFeatures(audioData) {
        // 1. RMSèƒ½é‡
        const rmsEnergy = Math.sqrt(audioData.reduce((sum, val) => sum + val * val, 0) / audioData.length);

        // 2. æœ€å¤§å¹…åº¦
        const maxAmplitude = Math.max(...audioData.map(Math.abs));

        // 3. åŠ¨æ€èŒƒå›´
        const minAmplitude = Math.min(...audioData.map(Math.abs).filter(x => x > 0));
        const dynamicRange = maxAmplitude / Math.max(minAmplitude, 1e-10);

        return [
            rmsEnergy,
            maxAmplitude,
            Math.log(dynamicRange + 1)  // å¯¹æ•°ç¼©æ”¾
        ];
    }
}

// å¯¼å‡º
window.VoiceprintExtractor = VoiceprintExtractor;
