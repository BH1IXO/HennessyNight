/**
 * å¿«é€Ÿå£°çº¹ç‰¹å¾æå–å™¨ (ä¼˜åŒ–ç‰ˆ)
 * ä½¿ç”¨ç®€åŒ–ç®—æ³•æé«˜é€Ÿåº¦
 */

class VoiceprintExtractor {
    constructor() {
        this.audioContext = null;
        this.sampleRate = 16000;
    }

    /**
     * ä»éŸ³é¢‘æ–‡ä»¶æå–å£°çº¹ç‰¹å¾å‘é‡ (å¿«é€Ÿç‰ˆæœ¬)
     */
    async extractFromFile(audioFile) {
        console.log('ğŸ¤ å¼€å§‹æå–å£°çº¹ç‰¹å¾ (å¿«é€Ÿç‰ˆ)...');
        console.log('æ–‡ä»¶:', audioFile.name, (audioFile.size / 1024).toFixed(2) + 'KB');

        try {
            // 1. åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
            if (!this.audioContext) {
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            // 2. è¯»å–å¹¶è§£ç éŸ³é¢‘
            const arrayBuffer = await audioFile.arrayBuffer();
            const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);

            console.log('âœ… è§£ç æˆåŠŸ:', audioBuffer.duration.toFixed(2) + 's');

            // 3. è·å–éŸ³é¢‘æ•°æ®
            let audioData = this.getMonoChannel(audioBuffer);

            // ğŸ¯ éŸ³é¢‘å½’ä¸€åŒ–
            audioData = this.normalize(audioData);

            // 4. å¿«é€Ÿç‰¹å¾æå– (ä¸ä½¿ç”¨MFCC,ä½¿ç”¨ç®€åŒ–ç‰¹å¾)
            const features = this.extractSimpleFeatures(audioData, audioBuffer.sampleRate);

            console.log('âœ… ç‰¹å¾æå–å®Œæˆ! å‘é‡:', features.length, 'ç»´');

            return {
                vector: features,
                duration: audioBuffer.duration,
                sampleRate: audioBuffer.sampleRate,
                extractedAt: new Date().toISOString(),
                metadata: {
                    originalSampleRate: audioBuffer.sampleRate,
                    fileSize: audioFile.size,
                    fileType: audioFile.type,
                    fileName: audioFile.name
                }
            };

        } catch (error) {
            console.error('âŒ æå–å¤±è´¥:', error);
            throw error;
        }
    }

    /**
     * è·å–å•å£°é“
     */
    getMonoChannel(audioBuffer) {
        if (audioBuffer.numberOfChannels === 1) {
            return audioBuffer.getChannelData(0);
        }

        const length = audioBuffer.length;
        const mono = new Float32Array(length);
        for (let i = 0; i < length; i++) {
            let sum = 0;
            for (let c = 0; c < audioBuffer.numberOfChannels; c++) {
                sum += audioBuffer.getChannelData(c)[i];
            }
            mono[i] = sum / audioBuffer.numberOfChannels;
        }
        return mono;
    }

    /**
     * éŸ³é¢‘å½’ä¸€åŒ–
     */
    normalize(audioData) {
        let maxAbs = 0;
        for (let i = 0; i < audioData.length; i++) {
            const abs = Math.abs(audioData[i]);
            if (abs > maxAbs) maxAbs = abs;
        }

        if (maxAbs > 0) {
            const normalized = new Float32Array(audioData.length);
            for (let i = 0; i < audioData.length; i++) {
                normalized[i] = audioData[i] / maxAbs;
            }
            return normalized;
        }
        return audioData;
    }

    /**
     * æå–ç®€åŒ–ç‰¹å¾ (å¿«é€Ÿä½†æœ‰æ•ˆ)
     */
    extractSimpleFeatures(audioData, sampleRate) {
        const features = [];

        // 1. åˆ†æ®µç»Ÿè®¡ç‰¹å¾ (10æ®µ)
        const numSegments = 10;
        const segmentSize = Math.floor(audioData.length / numSegments);

        for (let i = 0; i < numSegments; i++) {
            const start = i * segmentSize;
            const end = Math.min(start + segmentSize, audioData.length);
            const segment = audioData.slice(start, end);

            // å‡å€¼
            const mean = this.mean(segment);
            // æ–¹å·®
            const variance = this.variance(segment, mean);
            // RMSèƒ½é‡
            const rms = this.rms(segment);
            // è¿‡é›¶ç‡
            const zcr = this.zeroCrossingRate(segment);

            features.push(mean, variance, rms, zcr);
        }

        // 2. å…¨å±€ç‰¹å¾
        features.push(
            this.mean(audioData),
            this.variance(audioData),
            this.rms(audioData),
            this.zeroCrossingRate(audioData),
            this.maxAmplitude(audioData),
            this.dynamicRange(audioData)
        );

        // 3. é¢‘ç‡ç‰¹å¾ (ç®€åŒ–ç‰ˆ - ä½¿ç”¨Web Audio APIçš„AnalyserNode)
        const freqFeatures = this.extractFrequencyFeatures(audioData, sampleRate);
        features.push(...freqFeatures);

        return features;
    }

    /**
     * å‡å€¼
     */
    mean(data) {
        let sum = 0;
        for (let i = 0; i < data.length; i++) {
            sum += data[i];
        }
        return sum / data.length;
    }

    /**
     * æ–¹å·®
     */
    variance(data, mean = null) {
        if (mean === null) mean = this.mean(data);
        let sumSq = 0;
        for (let i = 0; i < data.length; i++) {
            const diff = data[i] - mean;
            sumSq += diff * diff;
        }
        return sumSq / data.length;
    }

    /**
     * RMSèƒ½é‡
     */
    rms(data) {
        let sumSq = 0;
        for (let i = 0; i < data.length; i++) {
            sumSq += data[i] * data[i];
        }
        return Math.sqrt(sumSq / data.length);
    }

    /**
     * è¿‡é›¶ç‡
     */
    zeroCrossingRate(data) {
        let crossings = 0;
        for (let i = 1; i < data.length; i++) {
            if ((data[i] >= 0 && data[i - 1] < 0) || (data[i] < 0 && data[i - 1] >= 0)) {
                crossings++;
            }
        }
        return crossings / data.length;
    }

    /**
     * æœ€å¤§å¹…åº¦
     */
    maxAmplitude(data) {
        let max = 0;
        for (let i = 0; i < data.length; i++) {
            max = Math.max(max, Math.abs(data[i]));
        }
        return max;
    }

    /**
     * åŠ¨æ€èŒƒå›´
     */
    dynamicRange(data) {
        const max = this.maxAmplitude(data);
        let min = Infinity;
        for (let i = 0; i < data.length; i++) {
            const abs = Math.abs(data[i]);
            if (abs > 0) {
                min = Math.min(min, abs);
            }
        }
        return Math.log(max / Math.max(min, 1e-10) + 1);
    }

    /**
     * é¢‘ç‡ç‰¹å¾ (ç®€åŒ–ç‰ˆ)
     */
    extractFrequencyFeatures(audioData, sampleRate) {
        // ä½¿ç”¨ç®€å•çš„é¢‘å¸¦èƒ½é‡åˆ†æ
        const features = [];

        // åˆ†æˆ4ä¸ªé¢‘å¸¦
        const numBands = 4;
        const bandSize = Math.floor(audioData.length / numBands);

        for (let i = 0; i < numBands; i++) {
            const start = i * bandSize;
            const end = Math.min(start + bandSize, audioData.length);
            const band = audioData.slice(start, end);

            // è®¡ç®—é¢‘å¸¦èƒ½é‡
            const energy = this.rms(band);
            features.push(energy);
        }

        // é¢‘è°±è´¨å¿ƒä¼°è®¡ (ç®€åŒ–ç‰ˆ)
        let weightedSum = 0;
        let totalEnergy = 0;
        for (let i = 0; i < audioData.length; i++) {
            const energy = audioData[i] * audioData[i];
            weightedSum += i * energy;
            totalEnergy += energy;
        }
        const spectralCentroid = weightedSum / Math.max(totalEnergy, 1e-10);
        features.push(spectralCentroid / audioData.length);

        return features;
    }

    /**
     * ä»éŸ³é¢‘æ•°æ®æå– (å®æ—¶ç”¨)
     */
    extractFromAudioData(audioData, sampleRate = 16000) {
        try {
            const features = this.extractSimpleFeatures(audioData, sampleRate);
            return features;
        } catch (error) {
            console.error('å®æ—¶æå–å¤±è´¥:', error);
            return null;
        }
    }
}

// å¯¼å‡º
window.VoiceprintExtractor = VoiceprintExtractor;
console.log('âœ… å¿«é€Ÿå£°çº¹æå–å™¨å·²åŠ è½½');
