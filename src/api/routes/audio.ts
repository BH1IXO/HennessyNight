/**
 * éŸ³é¢‘å¤„ç†è·¯ç”±
 */

import { Router, Request, Response } from 'express';
import { PrismaClient, Prisma } from '@prisma/client';
import { asyncHandler, createError } from '../middleware/errorHandler';
import { uploadRateLimiter } from '../middleware/rateLimiter';
import multer from 'multer';
import path from 'path';
import fs from 'fs/promises';
import { AudioProcessor } from '@/services/audio/AudioProcessor';
import audioConverter from '@/services/audio/AudioConverter';
import { speakerStorage } from '@/services/storage/SpeakerStorage';

const router = Router();
const prisma = new PrismaClient();
const audioProcessor = new AudioProcessor();

// é…ç½®æ–‡ä»¶ä¸Šä¼ 
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, path.join(process.cwd(), 'temp', 'uploads'));
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = `${Date.now()}-${Math.round(Math.random() * 1E9)}`;
    cb(null, `${uniqueSuffix}${path.extname(file.originalname)}`);
  }
});

const upload = multer({
  storage,
  limits: {
    fileSize: 100 * 1024 * 1024 // 100MB
  },
  fileFilter: (req, file, cb) => {
    const allowedTypes = /mp3|wav|m4a|aac|ogg|webm/;
    const extname = allowedTypes.test(path.extname(file.originalname).toLowerCase());
    const mimetype = allowedTypes.test(file.mimetype);

    if (extname && mimetype) {
      cb(null, true);
    } else {
      cb(new Error('Only audio files are allowed'));
    }
  }
});

/**
 * POST /api/v1/audio/upload
 * ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
 */
router.post(
  '/upload',
  uploadRateLimiter,
  upload.single('audio'),
  asyncHandler(async (req: Request, res: Response) => {
    if (!req.file) {
      throw createError('No file uploaded', 400, 'NO_FILE');
    }

    const { meetingId } = req.body;

    if (!meetingId) {
      throw createError('meetingId is required', 400, 'INVALID_INPUT');
    }

    // è·å–éŸ³é¢‘ä¿¡æ¯
    const audioInfo = await audioProcessor.getAudioInfo(req.file.path);

    // ä¿å­˜åˆ°æ•°æ®åº“
    const audioFile = await prisma.audioFile.create({
      data: {
        meetingId,
        filename: req.file.originalname,
        filePath: req.file.path,
        size: req.file.size,
        mimeType: req.file.mimetype,
        duration: audioInfo.duration,
        processingStatus: 'PENDING'
      }
    });

    res.status(201).json({
      message: 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸ',
      data: audioFile
    });
  })
);

/**
 * POST /api/v1/audio/process
 * å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼ˆè½¬å½• + å£°çº¹è¯†åˆ«ï¼‰
 */
router.post('/process', asyncHandler(async (req: Request, res: Response) => {
  const { audioFileId, options = {} } = req.body;

  if (!audioFileId) {
    throw createError('audioFileId is required', 400, 'INVALID_INPUT');
  }

  // è·å–éŸ³é¢‘æ–‡ä»¶
  const audioFile = await prisma.audioFile.findUnique({
    where: { id: audioFileId }
  });

  if (!audioFile) {
    throw createError('Audio file not found', 404, 'AUDIO_NOT_FOUND');
  }

  // æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
  await prisma.audioFile.update({
    where: { id: audioFileId },
    data: { processingStatus: 'PROCESSING' }
  });

  // TODO: å¼‚æ­¥å¤„ç†éŸ³é¢‘
  // 1. è½¬æ¢æ ¼å¼
  // 2. è½¬å½•
  // 3. å£°çº¹è¯†åˆ«
  // 4. ä¿å­˜ç»“æœ

  res.json({
    message: 'éŸ³é¢‘å¤„ç†ä»»åŠ¡å·²æäº¤',
    data: { audioFileId, status: 'PROCESSING' }
  });
}));

/**
 * GET /api/v1/audio/:id/info
 * è·å–éŸ³é¢‘ä¿¡æ¯
 */
router.get('/:id/info', asyncHandler(async (req: Request, res: Response) => {
  const { id } = req.params;

  const audioFile = await prisma.audioFile.findUnique({
    where: { id }
  });

  if (!audioFile) {
    throw createError('Audio file not found', 404, 'AUDIO_NOT_FOUND');
  }

  res.json({ data: audioFile });
}));

/**
 * POST /api/v1/audio/transcribe
 * å®æ—¶è½¬å½•éŸ³é¢‘æµ
 */
router.post('/transcribe',
  upload.single('audio'),
  asyncHandler(async (req: Request, res: Response) => {
    if (!req.file) {
      throw createError('No audio file uploaded', 400, 'NO_FILE');
    }

    let audioFilePath = req.file.path;
    let convertedFilePath: string | null = null;

    try {
      // æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢éŸ³é¢‘æ ¼å¼
      console.log(`[Transcribe] æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶: ${audioFilePath}`);
      const needsConversion = await audioConverter.needsConversion(audioFilePath);

      if (needsConversion) {
        console.log(`[Transcribe] éœ€è¦è½¬æ¢éŸ³é¢‘æ ¼å¼`);
        convertedFilePath = await audioConverter.convertToVoskFormat({
          inputPath: audioFilePath
        });
        audioFilePath = convertedFilePath;
        console.log(`[Transcribe] éŸ³é¢‘è½¬æ¢å®Œæˆ: ${convertedFilePath}`);
      } else {
        console.log(`[Transcribe] éŸ³é¢‘æ ¼å¼æ­£ç¡®ï¼Œæ— éœ€è½¬æ¢`);
      }

      const { spawn } = require('child_process');
      // ğŸ”§ ä¸´æ—¶ä¿®å¤ï¼šä½¿ç”¨ç³»ç»ŸPython (è™šæ‹Ÿç¯å¢ƒpyannote-envä¸å­˜åœ¨)
      // const pythonPath = path.join(process.cwd(), 'python', 'pyannote-env', 'Scripts', 'python.exe');
      const pythonPath = 'python'; // ä½¿ç”¨ç³»ç»ŸPython
      const scriptPath = path.join(process.cwd(), 'python', 'vosk_recognizer.py');

      // è°ƒç”¨Pythonè„šæœ¬è¿›è¡Œè¯­éŸ³è¯†åˆ«
      const pythonProcess = spawn(pythonPath, [scriptPath, 'file', audioFilePath]);

      let results: any[] = [];

      pythonProcess.stdout.on('data', (data: Buffer) => {
        const lines = data.toString().trim().split('\n');
        lines.forEach(line => {
          if (line.trim()) {
            try {
              const result = JSON.parse(line);
              results.push(result);
            } catch (e) {
              // å¿½ç•¥æ— æ³•è§£æçš„è¡Œ
            }
          }
        });
      });

      pythonProcess.stderr.on('data', (data: Buffer) => {
        console.log(`[Vosk] ${data.toString()}`);
      });

      pythonProcess.on('close', async (code: number) => {
        if (code === 0) {
          // è½¬å½•æˆåŠŸåï¼Œè¿›è¡Œå£°çº¹æ¯”å¯¹ (ä½¿ç”¨WeSpeaker 256ç»´)
          try {
            console.log('[Transcribe] ====================');
            console.log('[Transcribe] ğŸ” å¼€å§‹å£°çº¹æ¯”å¯¹ (WeSpeaker 256ç»´)...');

            // ğŸ”¥ ä»JSONæ–‡ä»¶è¯»å–å£°çº¹æ•°æ® (ä¸å†ä½¿ç”¨Prisma)
            const speakers = await speakerStorage.getAllSpeakers();
            console.log(`[Transcribe] ====================`);
            console.log(`[Transcribe] ğŸ“Š ä»JSONåŠ è½½äº† ${speakers.length} ä¸ªå·²æ³¨å†Œå£°çº¹`);
            console.log(`[Transcribe] ğŸ“‹ å£°çº¹åˆ—è¡¨:`);
            speakers.forEach((s: any, i: number) => {
              const vpLength = s.voiceprintData?.features ? s.voiceprintData.features.length : 0;
              const sampleCount = s.samples ? s.samples.length : 0;
              console.log(`[Transcribe]   ${i + 1}. ${s.name} (${s.email}) - å‘é‡:${vpLength}ç»´, æ ·æœ¬æ•°:${sampleCount}`);
            });
            console.log(`[Transcribe] ====================`);

            let identifiedSpeaker: any = null;

            if (speakers.length > 0) {
              // ========== ğŸ”§ ä¿®å¤ï¼šåœ¨è¯†åˆ«å‰å…ˆè½¬æ¢éŸ³é¢‘æ ¼å¼ ==========
              let identifyAudioPath = audioFilePath;
              let identifyConvertedFilePath: string | null = null;

              try {
                console.log(`[Transcribe] æ£€æŸ¥éŸ³é¢‘æ ¼å¼: ${audioFilePath}`);
                const needsConversion = await audioConverter.needsConversion(audioFilePath);

                if (needsConversion) {
                  console.log('[Transcribe] éŸ³é¢‘éœ€è¦è½¬æ¢ä¸ºWAVæ ¼å¼è¿›è¡Œå£°çº¹è¯†åˆ«...');
                  identifyConvertedFilePath = await audioConverter.convertToVoskFormat({
                    inputPath: audioFilePath
                  });
                  identifyAudioPath = identifyConvertedFilePath;
                  console.log(`[Transcribe] éŸ³é¢‘è½¬æ¢å®Œæˆ: ${identifyAudioPath}`);
                } else {
                  console.log('[Transcribe] éŸ³é¢‘æ ¼å¼æ­£ç¡®ï¼Œæ— éœ€è½¬æ¢');
                }
              } catch (convertError) {
                console.error('[Transcribe] éŸ³é¢‘è½¬æ¢å¤±è´¥:', convertError);
                throw convertError;
              }

              // ğŸ”¥ ä½¿ç”¨WeSpeakeræå–å£°çº¹ç‰¹å¾
              const { spawn: spawnIdentify } = require('child_process');
              const pythonPath = path.join(process.cwd(), 'python', 'pyannote-env', 'Scripts', 'python.exe');
              const scriptPath = path.join(process.cwd(), 'python', 'wespeaker_service.py');

              const extractFeatures = (): Promise<any> => {
                return new Promise((resolve, reject) => {
                  const pythonProcess = spawnIdentify(pythonPath, [scriptPath, 'extract', identifyAudioPath, 'chinese', 'cpu']);

                  let stdout = '';
                  let stderr = '';

                  pythonProcess.stdout.on('data', (data: Buffer) => {
                    stdout += data.toString();
                  });

                  pythonProcess.stderr.on('data', (data: Buffer) => {
                    stderr += data.toString();
                  });

                  pythonProcess.on('close', async (code: number) => {
                    // åˆ é™¤å£°çº¹è¯†åˆ«ç”¨çš„è½¬æ¢åçš„ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                    if (identifyConvertedFilePath) {
                      try {
                        await audioConverter.cleanupConvertedFile(identifyConvertedFilePath);
                        console.log('[Transcribe] å·²æ¸…ç†å£°çº¹è¯†åˆ«ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶');
                      } catch (e) {
                        console.error('[Transcribe] æ¸…ç†å£°çº¹è¯†åˆ«ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å¤±è´¥:', e);
                      }
                    }

                    if (code === 0) {
                      try {
                        const result = JSON.parse(stdout);
                        resolve(result);
                      } catch (e) {
                        reject(new Error('Failed to parse WeSpeaker features'));
                      }
                    } else {
                      reject(new Error(`WeSpeaker process exited with code ${code}: ${stderr}`));
                    }
                  });

                  pythonProcess.on('error', (error: Error) => {
                    reject(error);
                  });
                });
              };

              const result = await extractFeatures();

              if (!result.success) {
                throw new Error('Feature extraction failed');
              }

              const userEmbedding = result.embedding;
              console.log(`[Transcribe] ====================`);
              console.log(`[Transcribe] âœ… WeSpeakerç‰¹å¾æå–å®Œæˆ: ${userEmbedding.length}ç»´`);
              console.log(`[Transcribe] ğŸ”¢ ç‰¹å¾å‘é‡é¢„è§ˆ: [${userEmbedding.slice(0, 5).map((v: number) => v.toFixed(4)).join(', ')}...]`);
              console.log(`[Transcribe] ====================`);
              console.log(`[Transcribe] ğŸ” å¼€å§‹å£°çº¹æ¯”å¯¹...`);

              // ğŸ”¥ è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
              const cosineSimilarity = (a: number[], b: number[]): number => {
                if (a.length !== b.length) return 0;
                let dotProduct = 0;
                let normA = 0;
                let normB = 0;
                for (let i = 0; i < a.length; i++) {
                  dotProduct += a[i] * b[i];
                  normA += a[i] * a[i];
                  normB += b[i] * b[i];
                }
                return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
              };

              // ğŸ”¥ åŒ¹é…è¯´è¯äºº
              let bestMatch: any = null;
              let bestSimilarity = 0;

              for (const speaker of speakers) {
                if (!speaker.voiceprintData?.features || speaker.voiceprintData.features.length === 0) {
                  console.log(`[Transcribe]   âš ï¸ ${speaker.name}: æ— å£°çº¹æ•°æ®ï¼Œè·³è¿‡`);
                  continue;
                }

                const similarity = cosineSimilarity(userEmbedding, speaker.voiceprintData.features);
                console.log(`[Transcribe]   ğŸ“Š ${speaker.name}: ${(similarity * 100).toFixed(2)}% (å‘é‡ç»´åº¦:${speaker.voiceprintData.features.length})`);

                if (similarity > bestSimilarity) {
                  bestSimilarity = similarity;
                  bestMatch = speaker;
                }
              }

              // ğŸ”¥ é˜ˆå€¼åˆ¤æ–­ (å®æ—¶éŸ³é¢‘ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼)
              const threshold = 0.32;  // é™ä½åˆ°32%ä»¥æé«˜å®æ—¶è¯†åˆ«ç‡
              console.log(`[Transcribe] ====================`);
              console.log(`[Transcribe] ğŸ¯ è¯†åˆ«é˜ˆå€¼: ${(threshold * 100).toFixed(0)}% (å®æ—¶æ¨¡å¼-å®½æ¾)`);
              console.log(`[Transcribe] ğŸ† æœ€é«˜ç›¸ä¼¼åº¦: ${bestMatch ? bestMatch.name : 'æ— '} - ${(bestSimilarity * 100).toFixed(2)}%`);

              if (bestMatch && bestSimilarity >= threshold) {
                console.log(`[Transcribe] âœ… è¯†åˆ«æˆåŠŸ: ${bestMatch.name} (${(bestSimilarity * 100).toFixed(2)}%)`);
                console.log(`[Transcribe] ====================`);
                identifiedSpeaker = {
                  id: bestMatch.id,
                  name: bestMatch.name,
                  confidence: bestSimilarity
                };
              } else {
                console.log(`[Transcribe] âŒ æœªåŒ¹é…åˆ°è¯´è¯äºº (æœ€é«˜ç›¸ä¼¼åº¦: ${(bestSimilarity * 100).toFixed(2)}% < é˜ˆå€¼${(threshold * 100).toFixed(0)}%)`);
                console.log(`[Transcribe] ====================`);
                identifiedSpeaker = {
                  name: 'æœªè¯†åˆ«è¯´è¯äºº',
                  confidence: bestSimilarity
                };
              }
            } else {
              console.log('[Transcribe] âš ï¸ æ²¡æœ‰å·²æ³¨å†Œçš„å£°çº¹');
              identifiedSpeaker = {
                name: 'æœªè¯†åˆ«è¯´è¯äºº',
                confidence: 0
              };
            }

            // æ¸…ç†è½¬æ¢åçš„ä¸´æ—¶æ–‡ä»¶
            if (convertedFilePath) {
              await audioConverter.cleanupConvertedFile(convertedFilePath);
            }

            res.json({
              message: 'è½¬å½•æˆåŠŸ',
              data: {
                results,
                speaker: identifiedSpeaker
              }
            });
          } catch (error: any) {
            console.error('[Transcribe] å£°çº¹è¯†åˆ«å¤±è´¥:', error);

            // å³ä½¿å£°çº¹è¯†åˆ«å¤±è´¥ï¼Œä¹Ÿè¿”å›è½¬å½•ç»“æœ
            // æ¸…ç†è½¬æ¢åçš„ä¸´æ—¶æ–‡ä»¶
            if (convertedFilePath) {
              await audioConverter.cleanupConvertedFile(convertedFilePath);
            }

            res.json({
              message: 'è½¬å½•æˆåŠŸï¼Œä½†å£°çº¹è¯†åˆ«å¤±è´¥',
              data: {
                results,
                speaker: {
                  name: 'æœªè¯†åˆ«è¯´è¯äºº',
                  confidence: 0,
                  error: error.message
                }
              }
            });
          }
        } else {
          // æ¸…ç†è½¬æ¢åçš„ä¸´æ—¶æ–‡ä»¶
          if (convertedFilePath) {
            await audioConverter.cleanupConvertedFile(convertedFilePath);
          }

          res.status(500).json({
            error: 'è½¬å½•å¤±è´¥',
            code
          });
        }
      });

      pythonProcess.on('error', async (error: Error) => {
        console.error('Pythonè¿›ç¨‹é”™è¯¯:', error);

        // æ¸…ç†è½¬æ¢åçš„ä¸´æ—¶æ–‡ä»¶
        if (convertedFilePath) {
          await audioConverter.cleanupConvertedFile(convertedFilePath);
        }

        res.status(500).json({
          error: 'è½¬å½•å¤±è´¥',
          message: error.message
        });
      });
    } catch (error: any) {
      console.error('[Transcribe] å¤„ç†å¤±è´¥:', error);

      // æ¸…ç†è½¬æ¢åçš„ä¸´æ—¶æ–‡ä»¶
      if (convertedFilePath) {
        await audioConverter.cleanupConvertedFile(convertedFilePath);
      }

      throw createError(`éŸ³é¢‘å¤„ç†å¤±è´¥: ${error.message}`, 500, 'PROCESSING_FAILED');
    }
  })
);

/**
 * POST /api/v1/audio/transcribe-file
 * è½¬å½•æ•´ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨FunASR + WeSpeakerå¤šè¯´è¯äººè¯†åˆ«ï¼‰
 */
router.post('/transcribe-file',
  upload.single('audio'),
  asyncHandler(async (req: Request, res: Response) => {
    if (!req.file) {
      throw createError('No audio file uploaded', 400, 'NO_FILE');
    }

    let audioFilePath = req.file.path;
    let convertedFilePath: string | null = null;

    try {
      console.log(`[TranscribeFile] å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶: ${req.file.originalname}`);

      // æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢éŸ³é¢‘æ ¼å¼ä¸º16kHzå•å£°é“WAV
      const needsConversion = await audioConverter.needsConversion(audioFilePath);
      if (needsConversion) {
        console.log(`[TranscribeFile] éœ€è¦è½¬æ¢éŸ³é¢‘æ ¼å¼`);
        convertedFilePath = await audioConverter.convertToVoskFormat({
          inputPath: audioFilePath
        });
        audioFilePath = convertedFilePath;
        console.log(`[TranscribeFile] éŸ³é¢‘è½¬æ¢å®Œæˆ: ${convertedFilePath}`);
      }

      // åŠ è½½å·²æ³¨å†Œçš„å£°çº¹æ•°æ®
      const speakers = await speakerStorage.findAll();
      console.log(`[TranscribeFile] ğŸ“‹ åŠ è½½äº† ${speakers.length} ä¸ªå·²æ³¨å†Œå£°çº¹`);

      // å‡†å¤‡å‚è€ƒå£°çº¹JSON
      const referenceEmbeddings: Record<string, number[]> = {};
      for (const speaker of speakers) {
        if (speaker.voiceprintData?.features && speaker.voiceprintData.features.length > 0) {
          referenceEmbeddings[speaker.name] = speaker.voiceprintData.features;
        }
      }
      const referenceJson = JSON.stringify(referenceEmbeddings);

      const { spawn } = require('child_process');
      const pythonPath = path.join(process.cwd(), 'python', 'pyannote-env', 'Scripts', 'python.exe');
      const scriptPath = path.join(process.cwd(), 'python', 'transcribe_with_speaker.py');

      // è°ƒç”¨Pythonè„šæœ¬è¿›è¡Œè½¬å½•+è¯´è¯äººè¯†åˆ«
      const pythonProcess = spawn(pythonPath, [
        scriptPath,
        audioFilePath,
        referenceJson,
        '0.40',  // threshold
        'chinese',
        'cpu'
      ]);

      let stdout = '';
      let stderr = '';

      pythonProcess.stdout.on('data', (data: Buffer) => {
        stdout += data.toString();
      });

      pythonProcess.stderr.on('data', (data: Buffer) => {
        stderr += data.toString();
        // å®æ—¶è¾“å‡ºPythonæ—¥å¿—
        const lines = stderr.trim().split('\n');
        lines.forEach(line => {
          if (line) console.log(`[TranscribeSpeaker/Python] ${line}`);
        });
      });

      pythonProcess.on('close', async (code: number) => {
        if (code !== 0) {
          console.error(`[TranscribeFile] Pythonè¿›ç¨‹é€€å‡º,ä»£ç : ${code}`);
          console.error(`[TranscribeFile] stderr:`, stderr);
          if (convertedFilePath) {
            await audioConverter.cleanupConvertedFile(convertedFilePath);
          }
          res.status(500).json({ error: 'è½¬å½•å¤±è´¥', code, stderr });
          return;
        }

        try {
          // è§£æPythonè„šæœ¬è¿”å›çš„JSONç»“æœ
          const result = JSON.parse(stdout);

          if (!result.success) {
            throw new Error(result.error || 'Transcription failed');
          }

          console.log(`[TranscribeFile] è½¬å½•å®Œæˆï¼Œå…± ${result.segments.length} ä¸ªåˆ†æ®µ`);

          // Pythonè„šæœ¬å·²ç»å®Œæˆäº†è½¬å½•å’Œè¯´è¯äººè¯†åˆ«,ç›´æ¥ä½¿ç”¨ç»“æœ
          // æ ¼å¼åŒ–segmentsä»¥åŒ¹é…å‰ç«¯æœŸæœ›çš„æ ¼å¼
          const segments = result.segments.map((seg: any) => ({
            text: seg.text,
            speaker: seg.speaker,
            timestamp: new Date(seg.start * 1000).toLocaleTimeString(),
            startTime: seg.start,
            endTime: seg.end
          }));

          console.log(`[TranscribeFile] å¤„ç†å®Œæˆï¼Œå…± ${segments.length} ä¸ªåˆ†æ®µ`);

          // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
          if (convertedFilePath) {
            await audioConverter.cleanupConvertedFile(convertedFilePath);
          }

          res.json({
            message: 'è½¬å½•æˆåŠŸ',
            data: {
              segments,
              totalSegments: segments.length,
              fullText: result.full_text || ''
            }
          });

        } catch (error: any) {
          console.error('[TranscribeFile] å¤„ç†å¤±è´¥:', error);

          if (convertedFilePath) {
            await audioConverter.cleanupConvertedFile(convertedFilePath);
          }

          res.status(500).json({
            error: 'å¤„ç†å¤±è´¥',
            message: error.message
          });
        }
      });

      pythonProcess.on('error', async (error: Error) => {
        console.error('[TranscribeFile] Pythonè¿›ç¨‹é”™è¯¯:', error);

        if (convertedFilePath) {
          await audioConverter.cleanupConvertedFile(convertedFilePath);
        }

        res.status(500).json({
          error: 'è½¬å½•å¤±è´¥',
          message: error.message
        });
      });

    } catch (error: any) {
      console.error('[TranscribeFile] å¤„ç†å¤±è´¥:', error);

      if (convertedFilePath) {
        await audioConverter.cleanupConvertedFile(convertedFilePath);
      }

      throw createError(`éŸ³é¢‘å¤„ç†å¤±è´¥: ${error.message}`, 500, 'PROCESSING_FAILED');
    }
  })
);

/**
 * POST /api/v1/audio/identify-speaker
 * å®æ—¶å£°çº¹è¯†åˆ« (ä½¿ç”¨WeSpeaker 256ç»´)
 */
router.post('/identify-speaker',
  (req, res, next) => {
    console.log('[IdentifySpeaker] âš¡ è¯·æ±‚åˆ°è¾¾è·¯ç”± (BEFORE multer middleware)');
    console.log('[IdentifySpeaker] Content-Type:', req.get('content-type'));
    console.log('[IdentifySpeaker] Method:', req.method);
    next();
  },
  (req, res, next) => {
    // Multerä¸­é—´ä»¶åŒ…è£… - ç”¨äºæ•è·multeré”™è¯¯
    const multerMiddleware = upload.single('audioFile');
    multerMiddleware(req, res, (err: any) => {
      if (err) {
        console.error('[IdentifySpeaker] âŒ Multeré”™è¯¯ - æ–‡ä»¶ä¸Šä¼ å¤±è´¥:');
        console.error('[IdentifySpeaker] é”™è¯¯ç±»å‹:', err.constructor.name);
        console.error('[IdentifySpeaker] é”™è¯¯æ¶ˆæ¯:', err.message);
        console.error('[IdentifySpeaker] é”™è¯¯ä»£ç :', err.code);
        console.error('[IdentifySpeaker] é”™è¯¯å­—æ®µ:', err.field);
        console.error('[IdentifySpeaker] å®Œæ•´é”™è¯¯:', err);
        return res.status(400).json({
          error: 'æ–‡ä»¶ä¸Šä¼ å¤±è´¥',
          message: err.message,
          code: err.code || 'MULTER_ERROR'
        });
      }
      console.log('[IdentifySpeaker] âœ… Multerå¤„ç†å®Œæˆ');
      console.log('[IdentifySpeaker] æ–‡ä»¶æ˜¯å¦å­˜åœ¨:', !!req.file);
      if (req.file) {
        console.log('[IdentifySpeaker] æ–‡ä»¶ä¿¡æ¯:', {
          fieldname: req.file.fieldname,
          originalname: req.file.originalname,
          mimetype: req.file.mimetype,
          size: req.file.size
        });
      }
      next();
    });
  },
  asyncHandler(async (req: Request, res: Response) => {
    // ğŸ” æœ€æ—©æœŸæ—¥å¿— - æ£€æŸ¥æ˜¯å¦è¿›å…¥handler
    console.log('='.repeat(80));
    console.log('[IdentifySpeaker] ğŸš€ ENTRY POINT - è¿›å…¥è¯†åˆ«handler');
    console.log('[IdentifySpeaker] è¯·æ±‚æ—¶é—´:', new Date().toISOString());
    console.log('[IdentifySpeaker] è¯·æ±‚æ–¹æ³•:', req.method);
    console.log('[IdentifySpeaker] è¯·æ±‚è·¯å¾„:', req.path);
    console.log('[IdentifySpeaker] Content-Type:', req.get('content-type'));
    console.log('='.repeat(80));

    console.log('[IdentifySpeaker] å¼€å§‹å®æ—¶å£°çº¹è¯†åˆ«');

    const audioFile = req.file;
    const speakersData = req.body.speakers;

    console.log('[IdentifySpeaker] ğŸ“¥ æ¥æ”¶åˆ°çš„æ•°æ®:');
    console.log('[IdentifySpeaker]   - audioFile:', audioFile ? `å­˜åœ¨ (${audioFile.originalname}, ${audioFile.size} bytes)` : 'ä¸å­˜åœ¨');
    console.log('[IdentifySpeaker]   - speakersData:', speakersData ? `å­˜åœ¨ (é•¿åº¦:${speakersData.length})` : 'ä¸å­˜åœ¨');

    if (!audioFile) {
      throw createError('æœªæä¾›éŸ³é¢‘æ–‡ä»¶', 400, 'NO_AUDIO_FILE');
    }

    if (!speakersData) {
      throw createError('æœªæä¾›å£°çº¹æ•°æ®', 400, 'NO_SPEAKERS');
    }

    let convertedFilePath: string | null = null;

    try {
      const audioFilePath = audioFile.path;
      console.log(`[IdentifySpeaker] éŸ³é¢‘æ–‡ä»¶: ${audioFilePath}`);
      console.log(`[IdentifySpeaker] æ–‡ä»¶å¤§å°: ${audioFile.size} bytes`);

      // æ£€æŸ¥æ–‡ä»¶å¤§å° - æ‹’ç»å¤ªå°çš„æ–‡ä»¶(å¯èƒ½æŸåæˆ–å¤ªçŸ­)
      if (audioFile.size < 1000) {
        console.log(`[IdentifySpeaker] âš ï¸ éŸ³é¢‘æ–‡ä»¶å¤ªå° (${audioFile.size} bytes),è·³è¿‡è¯†åˆ«`);

        // æ¸…ç†æ–‡ä»¶
        setTimeout(async () => {
          try {
            await fs.unlink(audioFile.path).catch(() => {});
            console.log('[IdentifySpeaker] å°æ–‡ä»¶å·²æ¸…ç†');
          } catch (e) {
            console.error('[IdentifySpeaker] æ¸…ç†å°æ–‡ä»¶å¤±è´¥:', e);
          }
        }, 100);

        return res.json({
          success: true,
          data: {
            matched: false,
            message: 'éŸ³é¢‘å¤ªçŸ­,æ— æ³•è¯†åˆ«'
          }
        });
      }

      // è§£æå£°çº¹æ•°æ®
      const speakers = JSON.parse(speakersData);
      console.log(`[IdentifySpeaker] ====================`);
      console.log(`[IdentifySpeaker] ğŸ“Š å£°çº¹æ•°é‡: ${speakers.length}`);
      console.log(`[IdentifySpeaker] ğŸ“‹ å£°çº¹åˆ—è¡¨:`);
      speakers.forEach((s: any, i: number) => {
        const vpLength = s.voiceprint ? s.voiceprint.length : 0;
        console.log(`[IdentifySpeaker]   ${i + 1}. ${s.name} (ID:${s.id}) - å‘é‡ç»´åº¦:${vpLength}ç»´`);
      });
      console.log(`[IdentifySpeaker] ====================`);

      if (speakers.length === 0) {
        console.log(`[IdentifySpeaker] âš ï¸ æ²¡æœ‰æ³¨å†Œå£°çº¹ï¼Œè·³è¿‡è¯†åˆ«`);
        return res.json({
          success: true,
          data: {
            matched: false,
            message: 'æ²¡æœ‰æ³¨å†Œå£°çº¹'
          }
        });
      }

      // ğŸ¯ æ£€æŸ¥éŸ³é¢‘å‚æ•°å¹¶è½¬æ¢æ ¼å¼
      console.log(`[IdentifySpeaker] æ­£åœ¨æ£€æŸ¥éŸ³é¢‘å‚æ•°...`);
      try {
        const audioInfo = await audioConverter.getAudioInfo(audioFilePath);
        console.log(`[IdentifySpeaker] ğŸ“Š æ¥æ”¶åˆ°çš„éŸ³é¢‘å‚æ•°:`);
        console.log(`[IdentifySpeaker]   - æ ¼å¼: ${audioInfo.format}`);
        console.log(`[IdentifySpeaker]   - é‡‡æ ·ç‡: ${audioInfo.sampleRate}Hz`);
        console.log(`[IdentifySpeaker]   - å£°é“æ•°: ${audioInfo.channels}`);
        console.log(`[IdentifySpeaker]   - æ¯”ç‰¹ç‡: ${audioInfo.bitrate}`);
        console.log(`[IdentifySpeaker]   - æ—¶é•¿: ${audioInfo.duration.toFixed(2)}ç§’`);
      } catch (infoError) {
        console.warn(`[IdentifySpeaker] âš ï¸ æ— æ³•è·å–éŸ³é¢‘ä¿¡æ¯:`, infoError);
      }

      const needsConversion = await audioConverter.needsConversion(audioFilePath);
      let processedAudioPath = audioFilePath;

      if (needsConversion) {
        console.log(`[IdentifySpeaker] éœ€è¦è½¬æ¢éŸ³é¢‘æ ¼å¼ â†’ ç›®æ ‡: 16kHz, å•å£°é“, WAV`);
        convertedFilePath = await audioConverter.convertToVoskFormat({
          inputPath: audioFilePath
        });
        processedAudioPath = convertedFilePath;
        console.log(`[IdentifySpeaker] âœ… éŸ³é¢‘è½¬æ¢å®Œæˆ: ${convertedFilePath}`);
      } else {
        console.log(`[IdentifySpeaker] âœ… éŸ³é¢‘æ ¼å¼æ­£ç¡®,æ— éœ€è½¬æ¢`);
      }

      // ğŸ¯ ä½¿ç”¨å¤šè¯´è¯äººè¯†åˆ«æœåŠ¡
      const { spawn } = require('child_process');
      const pythonPath = path.join(process.cwd(), 'python', 'pyannote-env', 'Scripts', 'python.exe');
      const multiSpeakerScript = path.join(process.cwd(), 'python', 'multi_speaker_è¯†åˆ«.py');

      // å‡†å¤‡å‚è€ƒå£°çº¹JSON
      const referenceEmbeddings: Record<string, number[]> = {};
      for (const speaker of speakers) {
        if (speaker.voiceprint && speaker.voiceprint.length > 0) {
          referenceEmbeddings[speaker.name] = speaker.voiceprint;
        }
      }
      const referenceJson = JSON.stringify(referenceEmbeddings);

      console.log(`[IdentifySpeaker] ä½¿ç”¨å¤šè¯´è¯äººè¯†åˆ«æ¨¡å¼`);
      console.log(`[IdentifySpeaker] é˜ˆå€¼: 40% (é€‚åº”éŸ³é¢‘è´¨é‡å·®å¼‚)`);

      const identifyMultiSpeaker = (): Promise<any> => {
        return new Promise((resolve, reject) => {
          // ä½¿ç”¨å¤šè¯´è¯äººè¯†åˆ«: identify_multi <audio> <reference_json> [threshold] [chunk_duration] [model] [device]
          const pythonProcess = spawn(pythonPath, [
            multiSpeakerScript,
            'identify_multi',
            processedAudioPath,
            referenceJson,
            '0.40',  // threshold: 40%
            '4.0',   // chunk_duration: 4ç§’
            'chinese',
            'cpu'
          ]);

          let stdout = '';
          let stderr = '';

          pythonProcess.stdout.on('data', (data: Buffer) => {
            stdout += data.toString();
          });

          pythonProcess.stderr.on('data', (data: Buffer) => {
            stderr += data.toString();
            // å®æ—¶è¾“å‡ºPythonæ—¥å¿—
            const lines = stderr.trim().split('\n');
            lines.forEach(line => {
              if (line) console.log(`[IdentifySpeaker/Python] ${line}`);
            });
          });

          pythonProcess.on('close', (code: number) => {
            if (code === 0) {
              try {
                const result = JSON.parse(stdout);
                resolve(result);
              } catch (e) {
                reject(new Error('Failed to parse multi-speaker result'));
              }
            } else {
              reject(new Error(`Multi-speaker process exited with code ${code}`));
            }
          });

          pythonProcess.on('error', (error: Error) => {
            reject(error);
          });
        });
      };

      const result = await identifyMultiSpeaker();

      if (!result.success) {
        throw new Error('Multi-speaker identification failed');
      }

      console.log(`[IdentifySpeaker] ====================`);
      console.log(`[IdentifySpeaker] âœ… å¤šè¯´è¯äººè¯†åˆ«å®Œæˆ`);
      console.log(`[IdentifySpeaker] æ£€æµ‹åˆ° ${result.numDetectedSpeakers || 0} ä¸ªè¯´è¯äºº`);
      if (result.detectedSpeakers && result.detectedSpeakers.length > 0) {
        console.log(`[IdentifySpeaker] è¯´è¯äººåˆ—è¡¨: ${result.detectedSpeakers.join(', ')}`);
      }
      console.log(`[IdentifySpeaker] ====================`);

      // è½¬æ¢ç»“æœæ ¼å¼ä»¥å…¼å®¹ç°æœ‰ä»£ç 
      let bestMatch: any = null;
      let bestSimilarity = result.confidence || 0;
      let allScores: { name: string; similarity: number }[] = [];

      if (result.identified && result.profileId) {
        // æ‰¾åˆ°åŒ¹é…çš„speakerå¯¹è±¡
        bestMatch = speakers.find((s: any) => s.name === result.profileId);

        // æ„å»ºæ‰€æœ‰åˆ†æ•°åˆ—è¡¨
        if (result.candidates) {
          allScores = result.candidates.map((c: any) => ({
            name: c.profileId,
            similarity: c.confidence
          }));
        }
      }

      // ğŸ¯ é˜ˆå€¼åˆ¤æ–­ (å®æ—¶éŸ³é¢‘ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼)
      // æ³¨å†Œå£°çº¹æ—¶éŸ³è´¨å¥½: 0.4-0.5
      // å®æ—¶è¯†åˆ«éŸ³è´¨å·®: 0.30-0.35 (å®½æ¾)
      const threshold = 0.32;  // é™ä½åˆ°32%ä»¥æé«˜å®æ—¶è¯†åˆ«ç‡
      console.log(`[IdentifySpeaker] ====================`);
      console.log(`[IdentifySpeaker] ğŸ¯ è¯†åˆ«é˜ˆå€¼: ${(threshold * 100).toFixed(0)}% (å®æ—¶æ¨¡å¼-å®½æ¾)`);
      console.log(`[IdentifySpeaker] ğŸ† æœ€é«˜ç›¸ä¼¼åº¦: ${bestMatch ? bestMatch.name : 'æ— '} - ${(bestSimilarity * 100).toFixed(2)}%`);

      if (bestMatch && bestSimilarity >= threshold) {
        console.log(`[IdentifySpeaker] âœ… è¯†åˆ«æˆåŠŸ: ${bestMatch.name} (${(bestSimilarity * 100).toFixed(2)}%)`);
        console.log(`[IdentifySpeaker] ====================`);

        // å…ˆå‘é€å“åº”ï¼Œåœ¨å“åº”å®Œæˆåå†æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        const responseData = {
          success: true,
          data: {
            matched: true,
            speaker: bestMatch,
            similarity: bestSimilarity,
            allScores,
            // å¤šè¯´è¯äººæ£€æµ‹ä¿¡æ¯
            multiSpeaker: result.multiSpeaker || false,
            detectedSpeakers: result.detectedSpeakers || [bestMatch.name],
            numDetectedSpeakers: result.numDetectedSpeakers || 1,
            candidates: result.candidates || []
          }
        };

        // å»¶è¿Ÿæ¸…ç†æ–‡ä»¶ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        setTimeout(async () => {
          try {
            if (convertedFilePath) {
              await audioConverter.cleanupConvertedFile(convertedFilePath);
            }
            if (audioFile) {
              await fs.unlink(audioFile.path).catch(() => {});
            }
            console.log('[IdentifySpeaker] ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ');
          } catch (cleanupError) {
            console.error('[IdentifySpeaker] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', cleanupError);
          }
        }, 100);

        return res.json(responseData);
      } else {
        console.log(`[IdentifySpeaker] âŒ æœªåŒ¹é…åˆ°è¯´è¯äºº (æœ€é«˜ç›¸ä¼¼åº¦: ${(bestSimilarity * 100).toFixed(2)}% < é˜ˆå€¼${(threshold * 100).toFixed(0)}%)`);
        console.log(`[IdentifySpeaker] ====================`);

        // å…ˆå‘é€å“åº”ï¼Œåœ¨å“åº”å®Œæˆåå†æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        const responseData = {
          success: true,
          data: {
            matched: false,
            bestSimilarity: bestSimilarity,
            allScores,
            // å¤šè¯´è¯äººæ£€æµ‹ä¿¡æ¯
            multiSpeaker: false,
            detectedSpeakers: [],
            numDetectedSpeakers: 0,
            candidates: result.candidates || []
          }
        };

        // å»¶è¿Ÿæ¸…ç†æ–‡ä»¶ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        setTimeout(async () => {
          try {
            if (convertedFilePath) {
              await audioConverter.cleanupConvertedFile(convertedFilePath);
            }
            if (audioFile) {
              await fs.unlink(audioFile.path).catch(() => {});
            }
            console.log('[IdentifySpeaker] ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ');
          } catch (cleanupError) {
            console.error('[IdentifySpeaker] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', cleanupError);
          }
        }, 100);

        return res.json(responseData);
      }

    } catch (error: any) {
      console.error('='.repeat(80));
      console.error('[IdentifySpeaker] âŒ è¯†åˆ«å¤±è´¥ - è¯¦ç»†é”™è¯¯ä¿¡æ¯:');
      console.error('[IdentifySpeaker] é”™è¯¯æ¶ˆæ¯:', error.message);
      console.error('[IdentifySpeaker] é”™è¯¯ç±»å‹:', error.constructor.name);
      console.error('[IdentifySpeaker] é”™è¯¯æ ˆ:');
      console.error(error.stack);
      console.error('[IdentifySpeaker] audioFile å­˜åœ¨:', !!audioFile);
      console.error('[IdentifySpeaker] convertedFilePath:', convertedFilePath);
      console.error('='.repeat(80));

      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆé”™è¯¯è·¯å¾„ï¼‰- å»¶è¿Ÿæ¸…ç†é¿å…é˜»å¡å“åº”
      setTimeout(async () => {
        try {
          if (convertedFilePath) {
            await audioConverter.cleanupConvertedFile(convertedFilePath);
          }
          if (audioFile) {
            await fs.unlink(audioFile.path).catch(() => {});
          }
          console.log('[IdentifySpeaker] é”™è¯¯è·¯å¾„ä¸‹çš„æ–‡ä»¶æ¸…ç†å®Œæˆ');
        } catch (cleanupError) {
          console.error('[IdentifySpeaker] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', cleanupError);
        }
      }, 100);

      // âš ï¸ é‡è¦: å³ä½¿å‘ç”Ÿé”™è¯¯,ä¹Ÿè¿”å›200çŠ¶æ€ç å’Œ"æœªè¯†åˆ«"ç»“æœ
      // è¿™æ ·å‰ç«¯å¯ä»¥æ­£å¸¸æ›´æ–°UI,è€Œä¸æ˜¯æ˜¾ç¤ºé”™è¯¯çŠ¶æ€
      console.log('[IdentifySpeaker] ğŸ”„ è¿”å›"æœªè¯†åˆ«"å“åº”(é¿å…å‰ç«¯500é”™è¯¯)');
      return res.json({
        success: true,
        data: {
          matched: false,
          message: 'è¯†åˆ«å¤±è´¥',
          error: error.message
        }
      });
    }
  })
);

export default router;

