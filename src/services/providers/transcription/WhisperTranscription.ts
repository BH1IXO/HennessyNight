/**
 * Whisperè¯­éŸ³è¯†åˆ«Provider
 * ä½¿ç”¨OpenAI Whisperè¿›è¡Œæœ¬åœ°è¯­éŸ³è½¬æ–‡å­—
 */

import { spawn } from 'child_process';
import path from 'path';
import fs from 'fs/promises';
import { v4 as uuidv4 } from 'uuid';
import { ITranscriptionProvider, TranscriptResult, TranscriptionOptions } from '../types';

export interface WhisperConfig {
  modelSize?: 'tiny' | 'base' | 'small' | 'medium' | 'large';
  language?: string;
  device?: 'cpu' | 'cuda';
}

export class WhisperTranscriptionProvider implements ITranscriptionProvider {
  readonly name = 'Whisper Speech Recognition';
  readonly type = 'whisper' as const;

  private config: WhisperConfig;
  private pythonPath: string;
  private tempDir: string;

  constructor(config: WhisperConfig = {}) {
    this.config = {
      modelSize: config.modelSize || 'base',
      language: config.language || 'zh',
      device: config.device || 'cpu'
    };

    // Pythonç¯å¢ƒè·¯å¾„
    const pythonEnvPath = path.join(process.cwd(), 'python', 'pyannote-env');
    this.pythonPath = path.join(
      pythonEnvPath,
      process.platform === 'win32' ? 'Scripts' : 'bin',
      process.platform === 'win32' ? 'python.exe' : 'python'
    );

    this.tempDir = path.join(process.cwd(), 'temp', 'whisper');
    this.initTempDir();
  }

  /**
   * è½¬å½•éŸ³é¢‘æ–‡ä»¶
   */
  async transcribeFile(
    audioFile: Buffer,
    options?: TranscriptionOptions
  ): Promise<TranscriptResult> {
    try {
      console.log('ğŸ¤ å¼€å§‹Whisperè½¬å½•...');

      // ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
      const tempPath = await this.saveToTemp(audioFile);

      // è°ƒç”¨Pythonè„šæœ¬è¿›è¡Œè½¬å½•
      const result = await this.runWhisper(
        tempPath,
        options?.language || this.config.language!,
        this.config.modelSize!
      );

      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      await fs.unlink(tempPath).catch(() => {});

      console.log('âœ… Whisperè½¬å½•å®Œæˆ');

      return {
        text: result.text,
        segments: result.segments.map((seg: any) => ({
          text: seg.text,
          startTime: seg.start,
          endTime: seg.end,
          confidence: 1.0, // Whisperä¸æä¾›ç½®ä¿¡åº¦
          speaker: undefined
        })),
        language: result.language,
        duration: result.segments.length > 0
          ? result.segments[result.segments.length - 1].end
          : 0
      };

    } catch (error: any) {
      console.error('âŒ Whisperè½¬å½•å¤±è´¥:', error);
      throw new Error(`Whisperè½¬å½•å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * è¿è¡ŒWhisper Pythonè„šæœ¬
   */
  private runWhisper(
    audioPath: string,
    language: string,
    modelSize: string
  ): Promise<any> {
    return new Promise((resolve, reject) => {
      const scriptPath = path.join(process.cwd(), 'python', 'whisper_service.py');

      console.log(`ğŸ“ è°ƒç”¨Whisper: ${modelSize} æ¨¡å‹, è¯­è¨€: ${language}`);

      const python = spawn(this.pythonPath, [
        scriptPath,
        audioPath,
        language,
        modelSize
      ]);

      let output = '';
      let errorOutput = '';

      python.stdout.on('data', (data) => {
        output += data.toString();
      });

      python.stderr.on('data', (data) => {
        const msg = data.toString();
        errorOutput += msg;
        // è¾“å‡ºè¿›åº¦ä¿¡æ¯
        if (msg.includes('æ­£åœ¨') || msg.includes('âœ…')) {
          console.log(msg.trim());
        }
      });

      python.on('close', (code) => {
        if (code !== 0) {
          reject(new Error(`Whisperæ‰§è¡Œå¤±è´¥ (é€€å‡ºç : ${code})\n${errorOutput}`));
          return;
        }

        try {
          const result = JSON.parse(output);

          if (!result.success) {
            reject(new Error(result.error));
            return;
          }

          resolve(result);
        } catch (error) {
          reject(new Error(`è§£æWhisperç»“æœå¤±è´¥: ${output}`));
        }
      });

      python.on('error', (error) => {
        reject(new Error(`å¯åŠ¨Pythonè¿›ç¨‹å¤±è´¥: ${error.message}`));
      });
    });
  }

  /**
   * ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
   */
  private async saveToTemp(audioData: Buffer): Promise<string> {
    const filename = `whisper_${uuidv4()}.wav`;
    const filepath = path.join(this.tempDir, filename);
    await fs.writeFile(filepath, audioData);
    return filepath;
  }

  /**
   * åˆå§‹åŒ–ä¸´æ—¶ç›®å½•
   */
  private async initTempDir(): Promise<void> {
    try {
      await fs.mkdir(this.tempDir, { recursive: true });
    } catch (error) {
      console.error('åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥:', error);
    }
  }

  /**
   * å¥åº·æ£€æŸ¥
   */
  async healthCheck(): Promise<boolean> {
    try {
      // æ£€æŸ¥Pythonç¯å¢ƒ
      const checkPython = spawn(this.pythonPath, ['--version']);

      return new Promise((resolve) => {
        checkPython.on('close', (code) => {
          resolve(code === 0);
        });

        checkPython.on('error', () => {
          resolve(false);
        });
      });
    } catch {
      return false;
    }
  }

  /**
   * Whisperä¸æ”¯æŒå®æ—¶è½¬å½•
   */
  async startRealtime(): Promise<void> {
    throw new Error('Whisperä¸æ”¯æŒå®æ—¶è½¬å½•ï¼Œè¯·ä½¿ç”¨ transcribeFile æ–¹æ³•å¤„ç†éŸ³é¢‘æ–‡ä»¶');
  }

  async sendAudio(): Promise<void> {
    throw new Error('Whisperä¸æ”¯æŒå®æ—¶è½¬å½•');
  }

  async stopRealtime(): Promise<void> {
    throw new Error('Whisperä¸æ”¯æŒå®æ—¶è½¬å½•');
  }
}

export default WhisperTranscriptionProvider;
