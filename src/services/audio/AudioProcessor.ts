/**
 * éŸ³é¢‘å¤„ç†æœåŠ¡
 * æä¾›éŸ³é¢‘æ ¼å¼è½¬æ¢ã€é‡‡æ ·ç‡è°ƒæ•´ã€é™å™ªç­‰åŠŸèƒ½
 */

import ffmpeg from 'fluent-ffmpeg';
import { Readable, PassThrough } from 'stream';
import path from 'path';
import fs from 'fs/promises';
import { v4 as uuidv4 } from 'uuid';

export interface AudioInfo {
  duration: number;      // æ—¶é•¿ï¼ˆç§’ï¼‰
  sampleRate: number;    // é‡‡æ ·ç‡
  channels: number;      // å£°é“æ•°
  bitrate: number;       // æ¯”ç‰¹ç‡
  format: string;        // æ ¼å¼
  size: number;          // æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
}

export interface ConvertOptions {
  format?: 'wav' | 'mp3' | 'flac' | 'ogg';
  sampleRate?: number;   // é‡‡æ ·ç‡ï¼Œå¦‚16000
  channels?: number;     // å£°é“æ•°ï¼Œ1=å•å£°é“ï¼Œ2=ç«‹ä½“å£°
  bitrate?: string;      // æ¯”ç‰¹ç‡ï¼Œå¦‚'128k'
  codec?: string;        // ç¼–ç å™¨
}

export interface AudioSegment {
  startTime: number;     // å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
  endTime: number;       // ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
  duration: number;      // æ—¶é•¿ï¼ˆç§’ï¼‰
  data?: Buffer;         // éŸ³é¢‘æ•°æ®
}

export class AudioProcessor {
  private tempDir: string;

  constructor(tempDir?: string) {
    this.tempDir = tempDir || path.join(process.cwd(), 'temp', 'audio');
    this.initTempDir();
  }

  /**
   * è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
   */
  async getAudioInfo(inputPath: string): Promise<AudioInfo> {
    return new Promise((resolve, reject) => {
      ffmpeg.ffprobe(inputPath, (err, metadata) => {
        if (err) {
          return reject(new Error(`è·å–éŸ³é¢‘ä¿¡æ¯å¤±è´¥: ${err.message}`));
        }

        const audioStream = metadata.streams.find(s => s.codec_type === 'audio');
        if (!audioStream) {
          return reject(new Error('æœªæ‰¾åˆ°éŸ³é¢‘æµ'));
        }

        resolve({
          duration: metadata.format.duration || 0,
          sampleRate: audioStream.sample_rate ? parseInt(String(audioStream.sample_rate)) : 0,
          channels: audioStream.channels || 0,
          bitrate: metadata.format.bit_rate ? parseInt(String(metadata.format.bit_rate)) : 0,
          format: metadata.format.format_name || '',
          size: metadata.format.size || 0
        });
      });
    });
  }

  /**
   * è½¬æ¢éŸ³é¢‘æ ¼å¼
   */
  async convert(
    input: string | Buffer,
    outputPath: string,
    options: ConvertOptions = {}
  ): Promise<string> {
    const {
      format = 'wav',
      sampleRate = 16000,
      channels = 1,
      bitrate = '256k',
      codec
    } = options;

    return new Promise(async (resolve, reject) => {
      try {
        let inputPath: string;

        // å¦‚æœè¾“å…¥æ˜¯Bufferï¼Œå…ˆä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        if (Buffer.isBuffer(input)) {
          inputPath = await this.saveToTemp(input);
        } else {
          inputPath = input;
        }

        const command = ffmpeg(inputPath)
          .toFormat(format)
          .audioFrequency(sampleRate)
          .audioChannels(channels);

        // å¯¹äºWAVæ ¼å¼ï¼Œä½¿ç”¨PCMç¼–ç 
        if (format === 'wav') {
          command.audioCodec('pcm_s16le');
        } else if (codec) {
          command.audioCodec(codec);
        }

        if (format !== 'wav') {
          command.audioBitrate(bitrate);
        }

        command
          .on('start', (commandLine) => {
            console.log(`ğŸµ æ‰§è¡Œå‘½ä»¤: ${commandLine}`);
          })
          .on('progress', (progress) => {
            if (progress.percent) {
              console.log(`â³ å¤„ç†è¿›åº¦: ${progress.percent.toFixed(1)}%`);
            }
          })
          .on('end', () => {
            console.log('âœ… éŸ³é¢‘è½¬æ¢å®Œæˆ');
            // å¦‚æœè¾“å…¥æ˜¯ä¸´æ—¶æ–‡ä»¶ï¼Œæ¸…ç†å®ƒ
            if (Buffer.isBuffer(input)) {
              fs.unlink(inputPath).catch(console.error);
            }
            resolve(outputPath);
          })
          .on('error', (err) => {
            reject(new Error(`éŸ³é¢‘è½¬æ¢å¤±è´¥: ${err.message}`));
          })
          .save(outputPath);
      } catch (error) {
        reject(error);
      }
    });
  }

  /**
   * è½¬æ¢ä¸ºæ ‡å‡†WAVæ ¼å¼ï¼ˆ16kHz, å•å£°é“, PCMï¼‰
   * è¿™æ˜¯å¤§å¤šæ•°è¯­éŸ³APIè¦æ±‚çš„æ ¼å¼
   */
  async convertToStandardWav(
    input: string | Buffer,
    outputPath?: string
  ): Promise<string> {
    const output = outputPath || path.join(this.tempDir, `${uuidv4()}.wav`);

    return this.convert(input, output, {
      format: 'wav',
      sampleRate: 16000,
      channels: 1,
      codec: 'pcm_s16le'
    });
  }

  /**
   * é™å™ªå¤„ç†
   */
  async denoise(inputPath: string, outputPath: string): Promise<string> {
    return new Promise((resolve, reject) => {
      ffmpeg(inputPath)
        .audioFilters([
          'highpass=f=200',    // é«˜é€šæ»¤æ³¢å™¨ï¼Œå»é™¤ä½é¢‘å™ªéŸ³
          'lowpass=f=3000',    // ä½é€šæ»¤æ³¢å™¨ï¼Œå»é™¤é«˜é¢‘å™ªéŸ³
          'afftdn=nf=-25'      // FFTé™å™ª
        ])
        .on('end', () => {
          console.log('âœ… é™å™ªå®Œæˆ');
          resolve(outputPath);
        })
        .on('error', (err) => {
          reject(new Error(`é™å™ªå¤±è´¥: ${err.message}`));
        })
        .save(outputPath);
    });
  }

  /**
   * éŸ³é‡å½’ä¸€åŒ–
   */
  async normalize(inputPath: string, outputPath: string): Promise<string> {
    return new Promise((resolve, reject) => {
      ffmpeg(inputPath)
        .audioFilters('loudnorm')
        .on('end', () => {
          console.log('âœ… éŸ³é‡å½’ä¸€åŒ–å®Œæˆ');
          resolve(outputPath);
        })
        .on('error', (err) => {
          reject(new Error(`éŸ³é‡å½’ä¸€åŒ–å¤±è´¥: ${err.message}`));
        })
        .save(outputPath);
    });
  }

  /**
   * è£å‰ªéŸ³é¢‘
   */
  async trim(
    inputPath: string,
    outputPath: string,
    startTime: number,
    duration: number
  ): Promise<string> {
    return new Promise((resolve, reject) => {
      ffmpeg(inputPath)
        .setStartTime(startTime)
        .setDuration(duration)
        .on('end', () => {
          console.log('âœ… è£å‰ªå®Œæˆ');
          resolve(outputPath);
        })
        .on('error', (err) => {
          reject(new Error(`è£å‰ªå¤±è´¥: ${err.message}`));
        })
        .save(outputPath);
    });
  }

  /**
   * åˆå¹¶å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
   */
  async merge(inputPaths: string[], outputPath: string): Promise<string> {
    return new Promise((resolve, reject) => {
      const command = ffmpeg();

      // æ·»åŠ æ‰€æœ‰è¾“å…¥æ–‡ä»¶
      inputPaths.forEach(path => {
        command.input(path);
      });

      command
        .on('end', () => {
          console.log('âœ… åˆå¹¶å®Œæˆ');
          resolve(outputPath);
        })
        .on('error', (err) => {
          reject(new Error(`åˆå¹¶å¤±è´¥: ${err.message}`));
        })
        .mergeToFile(outputPath, this.tempDir);
    });
  }

  /**
   * åˆ†å‰²éŸ³é¢‘ä¸ºå¤šä¸ªæ®µè½
   */
  async split(
    inputPath: string,
    segments: Array<{ start: number; end: number }>
  ): Promise<AudioSegment[]> {
    const results: AudioSegment[] = [];

    for (let i = 0; i < segments.length; i++) {
      const { start, end } = segments[i];
      const duration = end - start;
      const outputPath = path.join(this.tempDir, `segment_${i}_${uuidv4()}.wav`);

      await this.trim(inputPath, outputPath, start, duration);

      const data = await fs.readFile(outputPath);

      results.push({
        startTime: start,
        endTime: end,
        duration,
        data
      });

      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      await fs.unlink(outputPath);
    }

    return results;
  }

  /**
   * æ£€æµ‹é™éŸ³æ®µè½
   */
  async detectSilence(
    inputPath: string,
    threshold: number = -40,  // dB
    minDuration: number = 0.5 // ç§’
  ): Promise<Array<{ start: number; end: number }>> {
    return new Promise((resolve, reject) => {
      const silences: Array<{ start: number; end: number }> = [];
      let currentSilence: { start?: number; end?: number } = {};

      ffmpeg(inputPath)
        .audioFilters(`silencedetect=n=${threshold}dB:d=${minDuration}`)
        .on('stderr', (stderrLine) => {
          // è§£æffmpegè¾“å‡ºçš„é™éŸ³æ£€æµ‹ä¿¡æ¯
          const silenceStart = /silence_start: ([\d.]+)/.exec(stderrLine);
          const silenceEnd = /silence_end: ([\d.]+)/.exec(stderrLine);

          if (silenceStart) {
            currentSilence.start = parseFloat(silenceStart[1]);
          }
          if (silenceEnd && currentSilence.start !== undefined) {
            currentSilence.end = parseFloat(silenceEnd[1]);
            silences.push({
              start: currentSilence.start,
              end: currentSilence.end
            });
            currentSilence = {};
          }
        })
        .on('end', () => {
          resolve(silences);
        })
        .on('error', (err) => {
          reject(new Error(`é™éŸ³æ£€æµ‹å¤±è´¥: ${err.message}`));
        })
        // ä½¿ç”¨nullè¾“å‡ºï¼Œæˆ‘ä»¬åªéœ€è¦stderrä¿¡æ¯
        .output('pipe:1')
        .format('null')
        .run();
    });
  }

  /**
   * åŸºäºé™éŸ³æ£€æµ‹æ™ºèƒ½åˆ†æ®µ
   */
  async smartSegment(
    inputPath: string,
    minSegmentDuration: number = 1.0,   // æœ€å°æ®µè½é•¿åº¦ï¼ˆç§’ï¼‰
    maxSegmentDuration: number = 30.0,  // æœ€å¤§æ®µè½é•¿åº¦ï¼ˆç§’ï¼‰
    silenceThreshold: number = -40,     // é™éŸ³é˜ˆå€¼ï¼ˆdBï¼‰
    minSilenceDuration: number = 0.5    // æœ€å°é™éŸ³é•¿åº¦ï¼ˆç§’ï¼‰
  ): Promise<AudioSegment[]> {
    // 1. è·å–éŸ³é¢‘æ€»æ—¶é•¿
    const info = await this.getAudioInfo(inputPath);
    const totalDuration = info.duration;

    // 2. æ£€æµ‹é™éŸ³æ®µè½
    const silences = await this.detectSilence(
      inputPath,
      silenceThreshold,
      minSilenceDuration
    );

    console.log(`æ£€æµ‹åˆ° ${silences.length} ä¸ªé™éŸ³æ®µè½`);

    // 3. æ ¹æ®é™éŸ³æ®µè½ç”Ÿæˆåˆ†æ®µç‚¹
    const segments: Array<{ start: number; end: number }> = [];
    let currentStart = 0;

    for (const silence of silences) {
      const segmentDuration = silence.start - currentStart;

      // å¦‚æœå½“å‰æ®µè½è¾¾åˆ°æœ€å°é•¿åº¦ï¼Œä¸”æ²¡æœ‰è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œå°±åœ¨æ­¤å¤„åˆ†æ®µ
      if (segmentDuration >= minSegmentDuration) {
        segments.push({
          start: currentStart,
          end: silence.start
        });
        currentStart = silence.end;
      }

      // å¦‚æœå½“å‰æ®µè½è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œå¼ºåˆ¶åˆ†æ®µ
      if (silence.start - currentStart >= maxSegmentDuration) {
        segments.push({
          start: currentStart,
          end: currentStart + maxSegmentDuration
        });
        currentStart = currentStart + maxSegmentDuration;
      }
    }

    // å¤„ç†æœ€åä¸€æ®µ
    if (currentStart < totalDuration) {
      segments.push({
        start: currentStart,
        end: totalDuration
      });
    }

    console.log(`ç”Ÿæˆ ${segments.length} ä¸ªéŸ³é¢‘æ®µè½`);

    // 4. åˆ†å‰²éŸ³é¢‘
    return this.split(inputPath, segments);
  }

  /**
   * Bufferè½¬AudioStream
   */
  bufferToStream(buffer: Buffer): Readable {
    const stream = new Readable();
    stream.push(buffer);
    stream.push(null);
    return stream;
  }

  /**
   * ä¿å­˜Bufferåˆ°ä¸´æ—¶æ–‡ä»¶
   */
  private async saveToTemp(buffer: Buffer): Promise<string> {
    const filename = `temp_${uuidv4()}.audio`;
    const filepath = path.join(this.tempDir, filename);
    await fs.writeFile(filepath, buffer);
    return filepath;
  }

  /**
   * åˆå§‹åŒ–ä¸´æ—¶ç›®å½•
   */
  private async initTempDir(): Promise<void> {
    try {
      await fs.mkdir(this.tempDir, { recursive: true });
    } catch (error) {
      console.error('åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥:', error);
    }
  }

  /**
   * æ¸…ç†ä¸´æ—¶æ–‡ä»¶
   */
  async cleanTemp(olderThan: number = 3600000): Promise<void> {
    try {
      const files = await fs.readdir(this.tempDir);
      const now = Date.now();

      for (const file of files) {
        const filepath = path.join(this.tempDir, file);
        const stats = await fs.stat(filepath);

        // åˆ é™¤è¶…è¿‡æŒ‡å®šæ—¶é—´çš„æ–‡ä»¶
        if (now - stats.mtimeMs > olderThan) {
          await fs.unlink(filepath);
          console.log(`ğŸ—‘ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶: ${file}`);
        }
      }
    } catch (error) {
      console.error('æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', error);
    }
  }
}

export default AudioProcessor;
