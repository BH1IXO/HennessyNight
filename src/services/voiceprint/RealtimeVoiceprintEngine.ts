/**
 * å®æ—¶å£°çº¹è¯†åˆ«å¼•æ“ â­
 *
 * æ ¸å¿ƒåŠŸèƒ½ï¼š
 * 1. å®æ—¶éŸ³é¢‘æµå¤„ç†
 * 2. å®æ—¶è½¬å½•ï¼ˆè®¯é£ï¼‰+ å®æ—¶å£°çº¹è¯†åˆ«ï¼ˆpyannote.audioï¼‰
 * 3. è¯´è¯äººè¯†åˆ«ï¼šæ ¹æ®å£°çº¹åº“åŒ¹é…å·²æ³¨å†Œè¯´è¯äºº
 * 4. äº‹ä»¶é©±åŠ¨æ¶æ„ï¼Œå®æ—¶è¿”å›ç»“æœ
 *
 * å·¥ä½œæµç¨‹ï¼š
 * 1. æ¥æ”¶å®æ—¶éŸ³é¢‘æµ
 * 2. éŸ³é¢‘ç¼“å†²ä¸åˆ†å—
 * 3. å¹¶è¡Œå¤„ç†ï¼š
 *    - è®¯é£å®æ—¶è½¬å½• -> è·å–æ–‡æœ¬
 *    - pyannoteåˆ†ç¦»è¯´è¯äºº -> è·å–è¯´è¯äººç‰‡æ®µ
 * 4. å£°çº¹åŒ¹é…ï¼šå°†æ£€æµ‹åˆ°çš„è¯´è¯äººä¸æ•°æ®åº“è¿›è¡ŒåŒ¹é…
 * 5. åˆå¹¶ç»“æœï¼šæ–‡æœ¬ + è¯´è¯äººæ ‡ç­¾
 * 6. å®æ—¶æ¨é€ç»“æœ
 */

import { EventEmitter } from 'events';
import { PrismaClient } from '@prisma/client';
import { ITranscriptionProvider, IVoiceprintProvider } from '../providers/types';
import { AudioProcessor } from '../audio/AudioProcessor';
import path from 'path';
import fs from 'fs/promises';

// ============= ç±»å‹å®šä¹‰ =============

export interface RealtimeEngineConfig {
  // éŸ³é¢‘é…ç½®
  sampleRate: number;              // é‡‡æ ·ç‡ï¼Œé»˜è®¤16000
  channels: number;                // å£°é“æ•°ï¼Œé»˜è®¤1

  // ç¼“å†²é…ç½®
  bufferDuration: number;          // ç¼“å†²æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3ç§’
  processingInterval: number;      // å¤„ç†é—´éš”ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤1000ms

  // è¯†åˆ«é…ç½®
  identificationThreshold: number; // å£°çº¹åŒ¹é…é˜ˆå€¼ï¼Œé»˜è®¤0.75
  minSpeechDuration: number;       // æœ€å°æœ‰æ•ˆè¯­éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1ç§’

  // æ•°æ®åº“é…ç½®
  enableSpeakerEnrollment: boolean; // æ˜¯å¦è‡ªåŠ¨æ³¨å†Œæ–°è¯´è¯äºº
  candidateSpeakerIds?: string[];   // å€™é€‰è¯´è¯äººIDåˆ—è¡¨ï¼ˆç”¨äº1:Nè¯†åˆ«ï¼‰
}

export interface TranscriptSegment {
  text: string;                    // è½¬å½•æ–‡æœ¬
  startTime: number;               // å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
  endTime: number;                 // ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
  speakerId?: string;              // åŒ¹é…åˆ°çš„è¯´è¯äººID
  speakerName?: string;            // è¯´è¯äººå§“å
  confidence: number;              // è¯†åˆ«ç½®ä¿¡åº¦
  isUnknownSpeaker: boolean;       // æ˜¯å¦ä¸ºæœªçŸ¥è¯´è¯äºº
}

export interface RealtimeEngineEvents {
  'transcript': (segment: TranscriptSegment) => void;
  'speaker_identified': (speakerId: string, speakerName: string, confidence: number) => void;
  'speaker_unknown': (embeddingId: string) => void;
  'error': (error: Error) => void;
  'status': (status: EngineStatus) => void;
}

export enum EngineStatus {
  IDLE = 'idle',
  STARTING = 'starting',
  RUNNING = 'running',
  PAUSED = 'paused',
  STOPPING = 'stopping',
  ERROR = 'error'
}

// ============= å®æ—¶å£°çº¹è¯†åˆ«å¼•æ“ =============

export class RealtimeVoiceprintEngine extends EventEmitter {
  private prisma: PrismaClient;
  private transcriptionProvider: ITranscriptionProvider;
  private voiceprintProvider: IVoiceprintProvider;
  private audioProcessor: AudioProcessor;

  private config: RealtimeEngineConfig;
  private status: EngineStatus = EngineStatus.IDLE;

  // éŸ³é¢‘ç¼“å†²
  private audioBuffer: Buffer[] = [];
  private bufferStartTime: number = 0;
  private currentTime: number = 0;

  // å¤„ç†é˜Ÿåˆ—
  private processingTimer?: NodeJS.Timeout;
  private isProcessing: boolean = false;

  // ä¼šè¯ä¿¡æ¯
  private sessionId?: string;
  private meetingId?: string;

  // è¯´è¯äººç¼“å­˜
  private speakerCache: Map<string, { id: string; name: string; embedding: number[] }> = new Map();

  // ä¸´æ—¶æ–‡ä»¶
  private tempDir: string;

  constructor(
    transcriptionProvider: ITranscriptionProvider,
    voiceprintProvider: IVoiceprintProvider,
    config: Partial<RealtimeEngineConfig> = {}
  ) {
    super();

    this.prisma = new PrismaClient();
    this.transcriptionProvider = transcriptionProvider;
    this.voiceprintProvider = voiceprintProvider;
    this.audioProcessor = new AudioProcessor();

    // é…ç½®é»˜è®¤å€¼
    this.config = {
      sampleRate: 16000,
      channels: 1,
      bufferDuration: 3,
      processingInterval: 1000,
      identificationThreshold: 0.75,
      minSpeechDuration: 1.0,
      enableSpeakerEnrollment: false,
      ...config
    };

    this.tempDir = path.join(process.cwd(), 'temp', 'realtime');
    this.initTempDir();
  }

  // ============= å…¬å…±API =============

  /**
   * å¯åŠ¨å®æ—¶è¯†åˆ«å¼•æ“
   */
  async start(meetingId: string, candidateSpeakerIds?: string[]): Promise<void> {
    if (this.status === EngineStatus.RUNNING) {
      throw new Error('å¼•æ“å·²åœ¨è¿è¡Œä¸­');
    }

    try {
      this.setStatus(EngineStatus.STARTING);
      this.meetingId = meetingId;

      // è®¾ç½®å€™é€‰è¯´è¯äºº
      if (candidateSpeakerIds) {
        this.config.candidateSpeakerIds = candidateSpeakerIds;
      }

      // åŠ è½½å€™é€‰è¯´è¯äººå£°çº¹æ•°æ®åˆ°ç¼“å­˜
      await this.loadSpeakerCache();

      // å¯åŠ¨è½¬å½•æœåŠ¡
      await this.transcriptionProvider.startRealtime({
        onTranscript: (text, isFinal) => {
          this.handleTranscript(text, isFinal);
        },
        onError: (error) => {
          this.emit('error', error);
        },
        language: 'zh_cn',
        enablePunctuation: true,
        enableNumberConversion: true
      });

      // é‡ç½®çŠ¶æ€
      this.audioBuffer = [];
      this.bufferStartTime = Date.now();
      this.currentTime = 0;

      // å¯åŠ¨å¤„ç†å®šæ—¶å™¨
      this.processingTimer = setInterval(() => {
        this.processBuffer();
      }, this.config.processingInterval);

      this.setStatus(EngineStatus.RUNNING);
      console.log('âœ… å®æ—¶å£°çº¹è¯†åˆ«å¼•æ“å·²å¯åŠ¨');

    } catch (error) {
      this.setStatus(EngineStatus.ERROR);
      throw error;
    }
  }

  /**
   * åœæ­¢å®æ—¶è¯†åˆ«å¼•æ“
   */
  async stop(): Promise<void> {
    if (this.status !== EngineStatus.RUNNING) {
      return;
    }

    try {
      this.setStatus(EngineStatus.STOPPING);

      // å¤„ç†å‰©ä½™ç¼“å†²
      if (this.audioBuffer.length > 0) {
        await this.processBuffer();
      }

      // åœæ­¢è½¬å½•æœåŠ¡
      await this.transcriptionProvider.stopRealtime();

      // æ¸…ç†å®šæ—¶å™¨
      if (this.processingTimer) {
        clearInterval(this.processingTimer);
        this.processingTimer = undefined;
      }

      // æ¸…ç©ºç¼“å†²å’Œç¼“å­˜
      this.audioBuffer = [];
      this.speakerCache.clear();

      this.setStatus(EngineStatus.IDLE);
      console.log('âœ… å®æ—¶å£°çº¹è¯†åˆ«å¼•æ“å·²åœæ­¢');

    } catch (error) {
      this.setStatus(EngineStatus.ERROR);
      throw error;
    }
  }

  /**
   * å‘é€éŸ³é¢‘æ•°æ®
   */
  async sendAudio(audioData: Buffer): Promise<void> {
    if (this.status !== EngineStatus.RUNNING) {
      throw new Error('å¼•æ“æœªè¿è¡Œ');
    }

    try {
      // 1. å‘é€åˆ°è½¬å½•æœåŠ¡ï¼ˆå®æ—¶ï¼‰
      await this.transcriptionProvider.sendAudio(audioData);

      // 2. æ·»åŠ åˆ°ç¼“å†²åŒºï¼ˆç”¨äºå£°çº¹è¯†åˆ«ï¼‰
      this.audioBuffer.push(audioData);

      // 3. æ›´æ–°æ—¶é—´
      const audioDuration = audioData.length / (this.config.sampleRate * 2); // 16ä½PCM
      this.currentTime += audioDuration;

    } catch (error) {
      this.emit('error', error as Error);
    }
  }

  /**
   * æš‚åœ/æ¢å¤
   */
  pause(): void {
    if (this.status === EngineStatus.RUNNING) {
      this.setStatus(EngineStatus.PAUSED);
    }
  }

  resume(): void {
    if (this.status === EngineStatus.PAUSED) {
      this.setStatus(EngineStatus.RUNNING);
    }
  }

  /**
   * è·å–å½“å‰çŠ¶æ€
   */
  getStatus(): EngineStatus {
    return this.status;
  }

  // ============= æ ¸å¿ƒå¤„ç†é€»è¾‘ =============

  /**
   * å¤„ç†éŸ³é¢‘ç¼“å†²åŒº
   * å®šæœŸè§¦å‘ï¼Œè¿›è¡Œå£°çº¹è¯†åˆ«å’Œè¯´è¯äººåŒ¹é…
   */
  private async processBuffer(): Promise<void> {
    if (this.isProcessing || this.audioBuffer.length === 0) {
      return;
    }

    // æ£€æŸ¥ç¼“å†²æ—¶é•¿æ˜¯å¦è¶³å¤Ÿ
    const bufferDuration = this.audioBuffer.reduce((acc, buf) => {
      return acc + buf.length / (this.config.sampleRate * 2);
    }, 0);

    if (bufferDuration < this.config.bufferDuration) {
      return; // ç¼“å†²ä¸è¶³ï¼Œç­‰å¾…æ›´å¤šæ•°æ®
    }

    this.isProcessing = true;

    try {
      // 1. åˆå¹¶ç¼“å†²åŒºéŸ³é¢‘
      const audioData = Buffer.concat(this.audioBuffer);

      // 2. ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
      const tempAudioPath = await this.saveTempAudio(audioData);

      // 3. è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
      const processedAudioPath = path.join(
        this.tempDir,
        `processed_${Date.now()}.wav`
      );
      await this.audioProcessor.convertToStandardWav(tempAudioPath, processedAudioPath);

      // 4. æ‰§è¡Œè¯´è¯äººåˆ†ç¦»
      const diarizationResult = await this.voiceprintProvider.diarization(
        await fs.readFile(processedAudioPath)
      );

      console.log(`ğŸ“Š æ£€æµ‹åˆ° ${diarizationResult.numSpeakers} ä¸ªè¯´è¯äºº`);

      // 5. ä¸ºæ¯ä¸ªè¯´è¯äººç‰‡æ®µè¿›è¡Œè¯†åˆ«
      for (const segment of diarizationResult.segments) {
        await this.identifySpeakerSegment(
          processedAudioPath,
          segment,
          this.bufferStartTime
        );
      }

      // 6. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      await fs.unlink(tempAudioPath);
      await fs.unlink(processedAudioPath);

      // 7. æ¸…ç©ºç¼“å†²åŒº
      this.audioBuffer = [];
      this.bufferStartTime = Date.now();

    } catch (error) {
      console.error('âŒ ç¼“å†²å¤„ç†å¤±è´¥:', error);
      this.emit('error', error as Error);
    } finally {
      this.isProcessing = false;
    }
  }

  /**
   * è¯†åˆ«è¯´è¯äººç‰‡æ®µ
   */
  private async identifySpeakerSegment(
    audioPath: string,
    segment: any,
    bufferStartTime: number
  ): Promise<void> {
    try {
      // æ£€æŸ¥ç‰‡æ®µæ—¶é•¿
      const duration = segment.end - segment.start;
      if (duration < this.config.minSpeechDuration) {
        console.log(`â­ï¸  è·³è¿‡è¿‡çŸ­ç‰‡æ®µ: ${duration.toFixed(2)}s`);
        return;
      }

      // 1. æå–ç‰‡æ®µéŸ³é¢‘
      const segmentPath = path.join(this.tempDir, `segment_${Date.now()}.wav`);
      await this.audioProcessor.trim(audioPath, segmentPath, segment.start, duration);

      // 2. è¯»å–éŸ³é¢‘æ•°æ®
      const segmentData = await fs.readFile(segmentPath);

      // 3. æ‰§è¡Œè¯´è¯äººè¯†åˆ«
      let speakerId: string | undefined;
      let speakerName: string | undefined;
      let confidence: number = 0;
      let isUnknown = true;

      if (this.config.candidateSpeakerIds && this.config.candidateSpeakerIds.length > 0) {
        // 1:N è¯†åˆ«ï¼ˆæœ‰å€™é€‰è¯´è¯äººï¼‰
        const identifyResult = await this.voiceprintProvider.identifySpeaker(
          segmentData,
          this.config.candidateSpeakerIds
        );

        if (identifyResult.speakerId && identifyResult.confidence >= this.config.identificationThreshold) {
          speakerId = identifyResult.speakerId;
          confidence = identifyResult.confidence;
          isUnknown = false;

          // ä»ç¼“å­˜è·å–è¯´è¯äººä¿¡æ¯
          const cached = this.speakerCache.get(speakerId);
          if (cached) {
            speakerName = cached.name;
          } else {
            // ä»æ•°æ®åº“è·å–
            const speaker = await this.prisma.speaker.findUnique({
              where: { id: speakerId }
            });
            if (speaker) {
              speakerName = speaker.name;
            }
          }

          console.log(`âœ… è¯†åˆ«åˆ°è¯´è¯äºº: ${speakerName} (ç½®ä¿¡åº¦: ${(confidence * 100).toFixed(1)}%)`);
          this.emit('speaker_identified', speakerId, speakerName || 'Unknown', confidence);
        } else {
          console.log(`â“ æœªè¯†åˆ«åˆ°å·²æ³¨å†Œè¯´è¯äºº (ç½®ä¿¡åº¦: ${(identifyResult.confidence * 100).toFixed(1)}%)`);
          this.emit('speaker_unknown', segment.speaker);
        }
      } else {
        // çº¯è¯´è¯äººåˆ†ç¦»æ¨¡å¼ï¼ˆæ— å€™é€‰è¯´è¯äººï¼‰
        console.log(`ğŸ‘¤ æ£€æµ‹åˆ°è¯´è¯äºº: ${segment.speaker}`);
        this.emit('speaker_unknown', segment.speaker);
      }

      // 4. ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¦‚æœæœ‰ä¼šè®®IDï¼‰
      if (this.meetingId) {
        await this.saveTranscriptSegment({
          meetingId: this.meetingId,
          speakerId: speakerId,
          speakerLabel: speakerName || segment.speaker,
          text: '', // è½¬å½•æ–‡æœ¬ç”±handleTranscriptå¤„ç†
          startTime: segment.start,
          endTime: segment.end,
          confidence: confidence,
          isUnknown: isUnknown
        });
      }

      // 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      await fs.unlink(segmentPath);

    } catch (error) {
      console.error('âŒ è¯´è¯äººç‰‡æ®µè¯†åˆ«å¤±è´¥:', error);
      this.emit('error', error as Error);
    }
  }

  /**
   * å¤„ç†è½¬å½•ç»“æœ
   */
  private handleTranscript(text: string, isFinal: boolean): void {
    if (!isFinal) {
      return; // åªå¤„ç†æœ€ç»ˆç»“æœ
    }

    console.log(`ğŸ“ è½¬å½•: ${text}`);

    // è½¬å½•ç»“æœä¸å£°çº¹è¯†åˆ«ç»“æœçš„åˆå¹¶åœ¨æ•°æ®åº“å±‚é¢è¿›è¡Œ
    // è¿™é‡Œåªå‘å‡ºäº‹ä»¶ï¼Œå…·ä½“å…³è”ç”±ä¸Šå±‚ä¸šåŠ¡é€»è¾‘å¤„ç†

    // å¯ä»¥é€šè¿‡æ—¶é—´æˆ³åŒ¹é…è½¬å½•æ–‡æœ¬å’Œè¯´è¯äºº
    // è¿™éƒ¨åˆ†é€»è¾‘å¯ä»¥åœ¨åç»­ä¼˜åŒ–ä¸­å®ç°æ›´ç²¾ç¡®çš„å¯¹é½
  }

  // ============= è¾…åŠ©æ–¹æ³• =============

  /**
   * åŠ è½½è¯´è¯äººç¼“å­˜
   */
  private async loadSpeakerCache(): Promise<void> {
    if (!this.config.candidateSpeakerIds || this.config.candidateSpeakerIds.length === 0) {
      return;
    }

    try {
      const speakers = await this.prisma.speaker.findMany({
        where: {
          id: { in: this.config.candidateSpeakerIds },
          profileStatus: 'ENROLLED'
        }
      });

      for (const speaker of speakers) {
        if (speaker.voiceprintData) {
          const voiceprintData = speaker.voiceprintData as any;
          this.speakerCache.set(speaker.id, {
            id: speaker.id,
            name: speaker.name,
            embedding: voiceprintData.embedding || []
          });
        }
      }

      console.log(`âœ… åŠ è½½ ${this.speakerCache.size} ä¸ªè¯´è¯äººå£°çº¹æ•°æ®åˆ°ç¼“å­˜`);

    } catch (error) {
      console.error('âŒ åŠ è½½è¯´è¯äººç¼“å­˜å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * ä¿å­˜è½¬å½•ç‰‡æ®µåˆ°æ•°æ®åº“
   */
  private async saveTranscriptSegment(data: {
    meetingId: string;
    speakerId?: string;
    speakerLabel: string;
    text: string;
    startTime: number;
    endTime: number;
    confidence: number;
    isUnknown: boolean;
  }): Promise<void> {
    try {
      await this.prisma.transcriptMessage.create({
        data: {
          meetingId: data.meetingId,
          speakerId: data.speakerId,
          speakerLabel: data.speakerLabel,
          content: data.text,
          timestamp: new Date(this.bufferStartTime + data.startTime * 1000),
          confidence: data.confidence
        }
      });
    } catch (error) {
      console.error('âŒ ä¿å­˜è½¬å½•ç‰‡æ®µå¤±è´¥:', error);
    }
  }

  /**
   * ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
   */
  private async saveTempAudio(audioData: Buffer): Promise<string> {
    const filename = `audio_${Date.now()}.raw`;
    const filepath = path.join(this.tempDir, filename);
    await fs.writeFile(filepath, audioData);
    return filepath;
  }

  /**
   * åˆå§‹åŒ–ä¸´æ—¶ç›®å½•
   */
  private async initTempDir(): Promise<void> {
    try {
      await fs.mkdir(this.tempDir, { recursive: true });
    } catch (error) {
      console.error('åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥:', error);
    }
  }

  /**
   * è®¾ç½®çŠ¶æ€
   */
  private setStatus(status: EngineStatus): void {
    this.status = status;
    this.emit('status', status);
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async cleanup(): Promise<void> {
    await this.stop();
    await this.prisma.$disconnect();
  }
}

export default RealtimeVoiceprintEngine;
