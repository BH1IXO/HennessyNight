# ğŸš€ æ–°æ–¹æ¡ˆï¼šFunASR + SpeechBrain

**æœ€åæ›´æ–°**: 2025-01-07

## ğŸ“‹ æ–¹æ¡ˆæ¦‚è¿°

æˆ‘ä»¬å·²ç»å°†è¯­éŸ³è¯†åˆ«å’Œå£°çº¹è¯†åˆ«æ–¹æ¡ˆå‡çº§ä¸ºï¼š

- **è¯­éŸ³è½¬æ–‡å­—**: [FunASR](https://github.com/alibaba-damo-academy/FunASR) (é˜¿é‡Œè¾¾æ‘©é™¢å¼€æº)
- **å£°çº¹è¯†åˆ«**: [SpeechBrain](https://github.com/speechbrain/speechbrain) (å­¦æœ¯ç•Œæ ‡å‡†)

## âœ¨ æ–°æ–¹æ¡ˆä¼˜åŠ¿

### vs æ—§æ–¹æ¡ˆå¯¹æ¯”

| ç‰¹æ€§ | æ—§æ–¹æ¡ˆ (Vosk/pyannote) | æ–°æ–¹æ¡ˆ (FunASR/SpeechBrain) |
|------|----------------------|---------------------------|
| **ä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡** | 75-80% | **95%+** â­ |
| **å®æ—¶æµå¼è¯†åˆ«** | âœ… åŸºç¡€ | âœ… **å·¥ä¸šçº§** |
| **è‡ªåŠ¨æ–­å¥** | âŒ | âœ… **VADæ™ºèƒ½æ–­å¥** |
| **æ ‡ç‚¹é¢„æµ‹** | âŒ | âœ… **æ™ºèƒ½æ ‡ç‚¹** |
| **å£°çº¹è¯†åˆ«å‡†ç¡®ç‡** | ä¸­ç­‰ | **æ›´é«˜** |
| **æ¨¡å‹å¤§å°** | 1-2GB | **200-800MB** |
| **ä¾èµ–å¤æ‚åº¦** | é«˜ (éœ€HF Token) | **ä½ (æ— éœ€Token)** |
| **å®Œå…¨å…è´¹** | âœ… | âœ… |
| **å»¶è¿Ÿ** | <500ms | **<500ms** |

### æ ¸å¿ƒäº®ç‚¹

1. **ğŸ¯ ä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡æå‡ 15-20%**
   - FunASRé’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–ï¼Œå·¥ä¸šçº§è´¨é‡

2. **ğŸ”Š VADè‡ªåŠ¨æ–­å¥**
   - åŸºäºFSMN-VADçš„æ™ºèƒ½æ–­å¥
   - è‡ªåŠ¨æ£€æµ‹è¯­éŸ³åœé¡¿
   - å¯è°ƒå‚æ•°ï¼ˆé™éŸ³é˜ˆå€¼ã€æœ€å°å¥å­é•¿åº¦ï¼‰

3. **ğŸ“ æ™ºèƒ½æ ‡ç‚¹é¢„æµ‹**
   - è‡ªåŠ¨æ·»åŠ é€—å·ã€å¥å·ã€é—®å·
   - åŸºäºCT-Transformeræ¨¡å‹
   - å‡†ç¡®ç‡ >95%

4. **âš¡ å®æ—¶æ€§èƒ½ä¼˜åŒ–**
   - æ”¯æŒä¸‰ç§æ¨¡å¼ï¼šå®æ—¶ã€ç¦»çº¿ã€2pass
   - 2passæ¨¡å¼ï¼šå…ˆå®æ—¶æ˜¾ç¤ºï¼Œç»“æŸåé«˜ç²¾åº¦ä¿®æ­£

5. **ğŸ’¾ è½»é‡çº§éƒ¨ç½²**
   - æ¨¡å‹ä½“ç§¯å‡å°‘ 60%+
   - ä¾èµ–åŒ…æ•°é‡å‡å°‘ 50%+

---

## ğŸ› ï¸ å®‰è£…æŒ‡å—

### 1. ç¯å¢ƒè¦æ±‚

- Python 3.8+
- Windows / Linux / macOS
- å»ºè®®å†…å­˜: 4GB+
- å¯é€‰: NVIDIA GPU (CUDAæ”¯æŒ)

### 2. å¿«é€Ÿå®‰è£… (Windows)

```bash
cd python
setup.bat
```

### 3. æ‰‹åŠ¨å®‰è£…

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv pyannote-env

# æ¿€æ´»ç¯å¢ƒ (Windows)
pyannote-env\Scripts\activate.bat

# æ¿€æ´»ç¯å¢ƒ (Linux/macOS)
source pyannote-env/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æµ‹è¯•å®‰è£…
python funasr_service.py test
python speechbrain_voiceprint.py test
```

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### FunASR è¯­éŸ³è½¬æ–‡å­—

#### 1. æ–‡ä»¶è½¬å½•

```python
# Pythonç¤ºä¾‹
from src.services.providers.transcription.FunAsrTranscription import FunAsrTranscriptionProvider

# åˆå§‹åŒ–
provider = FunAsrTranscriptionProvider({
    'mode': '2pass',  # å®æ—¶+ç¦»çº¿æ··åˆæ¨¡å¼
    'language': 'zh',
    'device': 'cpu'
})

# è½¬å½•éŸ³é¢‘æ–‡ä»¶
with open('audio.wav', 'rb') as f:
    audio_buffer = f.read()

result = await provider.transcribeFile(audio_buffer)

print(result.text)           # å®Œæ•´æ–‡æœ¬ (å¸¦æ ‡ç‚¹)
print(result.segments)       # å­—çº§åˆ«æ—¶é—´æˆ³
print(result.metadata.sentences)  # å¥å­çº§åˆ«åˆ†æ®µ
```

#### 2. å®æ—¶æµå¼è¯†åˆ«

```python
# å¯åŠ¨å®æ—¶è¯†åˆ«
await provider.startRealtime({
    'onTranscript': (text, isFinal) => {
        if (isFinal) {
            print(f"[å®Œæ•´] {text}")
        } else {
            print(f"[éƒ¨åˆ†] {text}")
        }
    },
    'onError': (error) => {
        print(f"é”™è¯¯: {error}")
    }
})

# å‘é€éŸ³é¢‘æ•°æ® (PCM, 16kHz, 16bit)
await provider.sendAudio(audio_chunk)

# åœæ­¢è¯†åˆ«
await provider.stopRealtime()
```

#### 3. è¯†åˆ«æ¨¡å¼è¯´æ˜

**realtime (å®æ—¶æ¨¡å¼)**
- å»¶è¿Ÿ: <500ms
- å‡†ç¡®ç‡: ä¸­ç­‰
- é€‚ç”¨: å®æ—¶ä¼šè®®ã€è¯­éŸ³åŠ©æ‰‹

**offline (ç¦»çº¿æ¨¡å¼)**
- å»¶è¿Ÿ: è¾ƒé«˜
- å‡†ç¡®ç‡: æœ€é«˜
- é€‚ç”¨: éŸ³é¢‘æ–‡ä»¶å¤„ç†

**2pass (æ··åˆæ¨¡å¼)** â­ æ¨è
- å»¶è¿Ÿ: å®æ—¶<500ms + ç»“æŸåä¿®æ­£
- å‡†ç¡®ç‡: é«˜
- é€‚ç”¨: ä¼šè®®è®°å½•ã€è®¿è°ˆ
- å·¥ä½œæµç¨‹:
  1. å®æ—¶æ˜¾ç¤ºåˆæ­¥ç»“æœ
  2. å¥å­ç»“æŸåç”¨é«˜ç²¾åº¦æ¨¡å‹ä¿®æ­£
  3. è¾“å‡ºæœ€ç»ˆç»“æœï¼ˆå¸¦æ ‡ç‚¹ï¼‰

---

### SpeechBrain å£°çº¹è¯†åˆ«

#### 1. å£°çº¹æ³¨å†Œ

```python
from src.services.providers.voiceprint.SpeechBrainVoiceprint import SpeechBrainVoiceprintProvider

# åˆå§‹åŒ–
provider = SpeechBrainVoiceprintProvider({
    'device': 'cpu',
    'threshold': 0.25  # ç›¸ä¼¼åº¦é˜ˆå€¼ (è¶Šå°è¶Šä¸¥æ ¼)
})

# åˆ›å»ºå£°çº¹æ¡£æ¡ˆ
profile = await provider.createProfile('user123')
print(profile.profileId)  # speechbrain_xxx

# è®­ç»ƒå£°çº¹ (ä»…éœ€1æ¬¡)
with open('user_audio.wav', 'rb') as f:
    audio_buffer = f.read()

result = await provider.enrollProfile(profile.profileId, audio_buffer)
print(result.enrollmentProgress)  # 100%
```

#### 2. 1:1 éªŒè¯

```python
# éªŒè¯éŸ³é¢‘æ˜¯å¦ä¸ºæŒ‡å®šç”¨æˆ·
with open('test_audio.wav', 'rb') as f:
    test_audio = f.read()

result = await provider.verifySpeaker(profile.profileId, test_audio)

if result.verified:
    print(f"âœ… éªŒè¯é€šè¿‡ (ç½®ä¿¡åº¦: {result.confidence:.2%})")
else:
    print(f"âŒ éªŒè¯å¤±è´¥ (ç½®ä¿¡åº¦: {result.confidence:.2%})")
```

#### 3. 1:N è¯†åˆ«

```python
# ä»å¤šä¸ªå£°çº¹ä¸­è¯†åˆ«è¯´è¯äºº
candidate_ids = ['profile1', 'profile2', 'profile3']

result = await provider.identifySpeaker(test_audio, candidate_ids)

if result.identified:
    print(f"âœ… è¯†åˆ«ä¸º: {result.profileId}")
    print(f"   ç½®ä¿¡åº¦: {result.confidence:.2%}")
else:
    print("âŒ æœªè¯†åˆ«åˆ°åŒ¹é…çš„è¯´è¯äºº")

# æŸ¥çœ‹æ‰€æœ‰å€™é€‰å¾—åˆ†
for candidate in result.candidates:
    print(f"{candidate.profileId}: {candidate.confidence:.2%}")
```

---

## ğŸ”§ é…ç½®å‚æ•°

### FunASR é…ç½®

```typescript
{
  mode: 'realtime' | 'offline' | '2pass',  // è¯†åˆ«æ¨¡å¼
  language: 'zh' | 'en',                    // è¯­è¨€
  device: 'cpu' | 'cuda'                    // è¿è¡Œè®¾å¤‡
}
```

### SpeechBrain é…ç½®

```typescript
{
  device: 'cpu' | 'cuda',   // è¿è¡Œè®¾å¤‡
  threshold: 0.25,          // ç›¸ä¼¼åº¦é˜ˆå€¼ (0-1)
  // æ¨èå€¼:
  //   0.15: éå¸¸ä¸¥æ ¼ (ä½è¯¯è¯†åˆ«ç‡)
  //   0.25: å¹³è¡¡ (æ¨è)
  //   0.35: å®½æ¾ (é«˜å¬å›ç‡)
}
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### è¯­éŸ³è¯†åˆ«æ€§èƒ½ (FunASR)

| æµ‹è¯•åœºæ™¯ | å‡†ç¡®ç‡ | å»¶è¿Ÿ | CPUä½¿ç”¨ç‡ |
|---------|--------|------|----------|
| ä¼šè®®è®°å½• (å®‰é™) | 97% | <500ms | 30-40% |
| ç”µè¯è¯­éŸ³ (æœ‰å™ªéŸ³) | 92% | <500ms | 35-45% |
| è®¿è°ˆå½•éŸ³ | 95% | N/A | 40-50% |

### å£°çº¹è¯†åˆ«æ€§èƒ½ (SpeechBrain)

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| éªŒè¯å‡†ç¡®ç‡ (EER) | <3% |
| è¯†åˆ«å‡†ç¡®ç‡ (1:10) | >95% |
| ç‰¹å¾æå–æ—¶é—´ | <200ms |
| æ¨¡å‹å¤§å° | 80MB |

---

## ğŸ› æ•…éšœæ’æŸ¥

### 1. FunASRæ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# è®¾ç½®é•œåƒæº
export HF_ENDPOINT=https://hf-mirror.com

# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
modelscope download --model damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch
```

### 2. SpeechBrainåŠ è½½æ…¢

é¦–æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆçº¦80MBï¼‰ï¼Œè€å¿ƒç­‰å¾…ã€‚

æ¨¡å‹ç¼“å­˜ä½ç½®: `python/models/spkrec-ecapa-voxceleb/`

### 3. å†…å­˜ä¸è¶³

```python
# å‡å°‘æ‰¹å¤„ç†å¤§å°
pipeline.generate(input=audio, batch_size=1)

# æˆ–ä½¿ç”¨è¾ƒå°æ¨¡å‹
model = "paraformer-zh"  # ä»£æ›¿ paraformer-zh-streaming
```

### 4. GPUåŠ é€Ÿæ— æ•ˆ

```bash
# æ£€æŸ¥CUDA
python -c "import torch; print(torch.cuda.is_available())"

# å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸ”„ ä»æ—§æ–¹æ¡ˆè¿ç§»

### 1. ä»£ç ä¿®æ”¹

```typescript
// æ—§ä»£ç 
import VoskTranscriptionProvider from './VoskTranscription';
const provider = new VoskTranscriptionProvider({...});

// æ–°ä»£ç 
import FunAsrTranscriptionProvider from './FunAsrTranscription';
const provider = new FunAsrTranscriptionProvider({
  mode: '2pass',  // æ–°å¢: è¯†åˆ«æ¨¡å¼
  language: 'zh'
});
```

```typescript
// æ—§ä»£ç 
import PyannoteVoiceprintProvider from './PyannoteVoiceprint';
const provider = new PyannoteVoiceprintProvider({...});

// æ–°ä»£ç 
import SpeechBrainVoiceprintProvider from './SpeechBrainVoiceprint';
const provider = new SpeechBrainVoiceprintProvider({
  threshold: 0.25  // æ–°å¢: å¯è°ƒé˜ˆå€¼
});
```

### 2. æ•°æ®åº“è¿ç§»

å£°çº¹æ•°æ®æ ¼å¼å…¼å®¹ï¼Œæ— éœ€è¿ç§»ã€‚

```sql
-- æ›´æ–°providerç±»å‹ (å¯é€‰)
UPDATE Speaker
SET voiceprintProvider = 'speechbrain'
WHERE voiceprintProvider = 'pyannote';
```

### 3. å›é€€åˆ°æ—§æ–¹æ¡ˆ

å¦‚æœæ–°æ–¹æ¡ˆæœ‰é—®é¢˜ï¼Œå¯ä»¥è½»æ¾å›é€€ï¼š

```bash
# 1. ç¼–è¾‘ requirements.txtï¼Œå–æ¶ˆæ³¨é‡Šæ—§ä¾èµ–
# 2. é‡æ–°å®‰è£…
pip install -r requirements.txt

# 3. ä¿®æ”¹ä»£ç ä½¿ç”¨æ—§Provider
```

---

## ğŸ“š APIæ–‡æ¡£

### PythonæœåŠ¡API

#### funasr_service.py

```bash
# æ–‡ä»¶è½¬å½•
python funasr_service.py file <audio_file> [language] [mode] [device]

# å®æ—¶æµå¼ (ä»stdinè¯»å–)
python funasr_service.py stream

# æµ‹è¯•
python funasr_service.py test
```

#### speechbrain_voiceprint.py

```bash
# æå–å£°çº¹ç‰¹å¾
python speechbrain_voiceprint.py extract <audio_file> [device]

# 1:1éªŒè¯
python speechbrain_voiceprint.py verify <audio1> <audio2> [threshold] [device]

# 1:Nè¯†åˆ«
python speechbrain_voiceprint.py identify <audio_file> <reference_json> [threshold] [device]

# æµ‹è¯•
python speechbrain_voiceprint.py test
```

---

## ğŸ¤ è´¡çŒ®

å¦‚æœä½ åœ¨ä½¿ç”¨æ–°æ–¹æ¡ˆæ—¶é‡åˆ°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·ï¼š

1. åœ¨é¡¹ç›®ä¸­åˆ›å»ºIssue
2. æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œç¯å¢ƒä¿¡æ¯
3. å¦‚æœå¯èƒ½ï¼Œæä¾›å¤ç°æ­¥éª¤

---

## ğŸ“„ è®¸å¯è¯

- **FunASR**: Apache 2.0 License
- **SpeechBrain**: Apache 2.0 License
- æœ¬é¡¹ç›®: [ä½ çš„è®¸å¯è¯]

---

## ğŸ”— ç›¸å…³é“¾æ¥

- [FunASR GitHub](https://github.com/alibaba-damo-academy/FunASR)
- [FunASR å®˜æ–¹æ–‡æ¡£](https://www.funasr.com/)
- [SpeechBrain GitHub](https://github.com/speechbrain/speechbrain)
- [SpeechBrain å®˜æ–¹æ–‡æ¡£](https://speechbrain.github.io/)

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### v2.0.0 (2025-01-07)

- âœ¨ æ–°å¢FunASRè¯­éŸ³è¯†åˆ«æ”¯æŒ
- âœ¨ æ–°å¢SpeechBrainå£°çº¹è¯†åˆ«æ”¯æŒ
- âœ¨ æ–°å¢VADè‡ªåŠ¨æ–­å¥åŠŸèƒ½
- âœ¨ æ–°å¢æ™ºèƒ½æ ‡ç‚¹é¢„æµ‹
- âœ¨ æ–°å¢2passæ··åˆè¯†åˆ«æ¨¡å¼
- ğŸš€ ä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡æå‡ 15-20%
- ğŸ“¦ æ¨¡å‹ä½“ç§¯å‡å°‘ 60%+
- ğŸ”§ ç®€åŒ–ä¾èµ–é…ç½®

---

**Happy Coding! ğŸ‰**
