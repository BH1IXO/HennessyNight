# pyannote.audio å£°çº¹è¯†åˆ«é…ç½®æŒ‡å—

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### æœ€ä½è¦æ±‚ï¼ˆCPUæ¨¡å¼ï¼‰
- Python 3.8+
- 8GB RAM
- 10GB ç¡¬ç›˜ç©ºé—´
- å¤„ç†é€Ÿåº¦ï¼šçº¦ 60-120 ç§’/åˆ†é’ŸéŸ³é¢‘

### æ¨èé…ç½®ï¼ˆGPUæ¨¡å¼ï¼‰â­
- Python 3.8+
- NVIDIA GPU (2GB+ æ˜¾å­˜)
- CUDA 11.8+
- 16GB RAM
- 15GB ç¡¬ç›˜ç©ºé—´
- å¤„ç†é€Ÿåº¦ï¼šçº¦ 10-20 ç§’/åˆ†é’ŸéŸ³é¢‘

## ğŸš€ å¿«é€Ÿå®‰è£…

### Windows

```bash
# 1. è¿›å…¥pythonç›®å½•
cd meeting-system-backend\python

# 2. è¿è¡Œå®‰è£…è„šæœ¬
setup.bat

# 3. æ¿€æ´»ç¯å¢ƒ
pyannote-env\Scripts\activate.bat

# 4. æµ‹è¯•å®‰è£…
python test_pyannote.py
```

### Linux / macOS

```bash
# 1. è¿›å…¥pythonç›®å½•
cd meeting-system-backend/python

# 2. æ·»åŠ æ‰§è¡Œæƒé™
chmod +x setup.sh

# 3. è¿è¡Œå®‰è£…è„šæœ¬
./setup.sh

# 4. æ¿€æ´»ç¯å¢ƒ
source pyannote-env/bin/activate

# 5. æµ‹è¯•å®‰è£…
python test_pyannote.py
```

## ğŸ“¦ æ‰‹åŠ¨å®‰è£…

å¦‚æœè‡ªåŠ¨å®‰è£…è„šæœ¬å¤±è´¥ï¼Œå¯ä»¥æ‰‹åŠ¨å®‰è£…ï¼š

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv pyannote-env

# 2. æ¿€æ´»ç¯å¢ƒ
# Windows:
pyannote-env\Scripts\activate.bat
# Linux/Mac:
source pyannote-env/bin/activate

# 3. å®‰è£…PyTorch
# CPUç‰ˆæœ¬:
pip install torch torchvision torchaudio

# GPUç‰ˆæœ¬ (æ¨è):
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 4. å®‰è£…pyannote.audio
pip install -r requirements.txt

# 5. æµ‹è¯•
python test_pyannote.py
```

## ğŸ”§ é…ç½®è¯´æ˜

### 1. ç¯å¢ƒå˜é‡é…ç½®

åœ¨ `meeting-system-backend/.env` æ–‡ä»¶ä¸­é…ç½®ï¼š

```env
# pyannote.audioé…ç½®
PYANNOTE_DEVICE=cuda          # 'cuda' æˆ– 'cpu'
PYANNOTE_MODEL_PATH=pyannote/speaker-diarization
PYANNOTE_MIN_SPEAKERS=1
PYANNOTE_MAX_SPEAKERS=10
```

### 2. æ¨¡å‹é…ç½®

pyannote.audio éœ€è¦é¢„è®­ç»ƒæ¨¡å‹ï¼Œæœ‰ä¸¤ç§æ–¹å¼ï¼š

#### æ–¹å¼Aï¼šä½¿ç”¨HuggingFace Hubï¼ˆæ¨èï¼‰

```python
# éœ€è¦HuggingFace tokenï¼ˆå…è´¹æ³¨å†Œï¼‰
# è®¿é—®ï¼šhttps://huggingface.co/pyannote/speaker-diarization
# æ¥å—æ¨¡å‹è®¸å¯è¯
# ç”Ÿæˆtoken: https://huggingface.co/settings/tokens

# è®¾ç½®ç¯å¢ƒå˜é‡
export HF_TOKEN=your_huggingface_token
```

#### æ–¹å¼Bï¼šæœ¬åœ°æ¨¡å‹ï¼ˆæ— éœ€ç½‘ç»œï¼‰

```bash
# 1. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
# ä»HuggingFaceä¸‹è½½æˆ–ä½¿ç”¨å·²æœ‰æ¨¡å‹

# 2. æ”¾ç½®åˆ° models ç›®å½•
mkdir -p models/pyannote
# å¤åˆ¶æ¨¡å‹æ–‡ä»¶åˆ°è¿™ä¸ªç›®å½•

# 3. ä¿®æ”¹é…ç½®
PYANNOTE_MODEL_PATH=./models/pyannote/speaker-diarization
```

## ğŸ§ª æµ‹è¯•éªŒè¯

### åŸºç¡€æµ‹è¯•

```bash
python test_pyannote.py
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ… pyannote.audio ç‰ˆæœ¬: 3.1.1
âœ… PyTorch ç‰ˆæœ¬: 2.x.x
âœ… CUDA å¯ç”¨: True/False
âœ… ä½¿ç”¨è®¾å¤‡: cuda/cpu
```

### å®é™…éŸ³é¢‘æµ‹è¯•

å‡†å¤‡ä¸€ä¸ªæµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼š

```python
# test_diarization.py
from pyannote.audio import Pipeline
import torch

# åŠ è½½pipeline
pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization",
    use_auth_token="YOUR_HF_TOKEN"  # å¦‚æœéœ€è¦
)

# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
pipeline = pipeline.to(device)

# è¿è¡Œè¯´è¯äººåˆ†ç¦»
diarization = pipeline("test_audio.wav")

# æ‰“å°ç»“æœ
for turn, _, speaker in diarization.itertracks(yield_label=True):
    print(f"Speaker {speaker}: {turn.start:.1f}s - {turn.end:.1f}s")
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### CPUæ¨¡å¼ï¼ˆIntel i7ï¼‰
- å¤„ç†1åˆ†é’ŸéŸ³é¢‘ï¼šçº¦ 60-90 ç§’
- å†…å­˜å ç”¨ï¼šçº¦ 2-3 GB
- é€‚åˆï¼šæµ‹è¯•ã€å°è§„æ¨¡ä½¿ç”¨

### GPUæ¨¡å¼ï¼ˆNVIDIA RTX 3060ï¼‰
- å¤„ç†1åˆ†é’ŸéŸ³é¢‘ï¼šçº¦ 10-15 ç§’
- æ˜¾å­˜å ç”¨ï¼šçº¦ 1-2 GB
- å†…å­˜å ç”¨ï¼šçº¦ 2-3 GB
- é€‚åˆï¼šç”Ÿäº§ç¯å¢ƒã€å¤§è§„æ¨¡ä½¿ç”¨

### äº‘GPUæ–¹æ¡ˆï¼ˆæ¨èï¼‰

å¦‚æœæœ¬åœ°æ²¡æœ‰GPUï¼Œå¯ä»¥ä½¿ç”¨äº‘æœåŠ¡ï¼š

1. **AutoDL** (å›½å†…)
   - ä»·æ ¼ï¼šÂ¥2-4/å°æ—¶
   - GPUï¼šRTX 3080/3090
   - ç½‘ç«™ï¼šhttps://www.autodl.com/

2. **æ’æºäº‘**
   - ä»·æ ¼ï¼šÂ¥1-3/å°æ—¶
   - GPUï¼šRTX 3060/3080
   - ç½‘ç«™ï¼šhttps://gpushare.com/

3. **Colab** (å›½é™…)
   - å…è´¹ç‰ˆï¼šæ¯å¤©æœ‰é™GPUæ—¶é—´
   - ä»˜è´¹ç‰ˆï¼š$9.99/æœˆ
   - ç½‘ç«™ï¼šhttps://colab.research.google.com/

## ğŸ› å¸¸è§é—®é¢˜

### 1. å®‰è£…å¤±è´¥

**é—®é¢˜**ï¼š`pip install torch` å¤±è´¥

**è§£å†³**ï¼š
```bash
# æ›´æ¢æ¸…åæº
pip install torch -i https://pypi.tuna.tsinghua.edu.cn/simple

# æˆ–è€…æ‰‹åŠ¨ä¸‹è½½whlæ–‡ä»¶
# https://download.pytorch.org/whl/torch_stable.html
```

### 2. CUDAç‰ˆæœ¬ä¸åŒ¹é…

**é—®é¢˜**ï¼š`RuntimeError: CUDA error: no kernel image is available`

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvidia-smi

# å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„PyTorch
# CUDA 11.8:
pip install torch --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1:
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### 3. æ¨¡å‹ä¸‹è½½å¤±è´¥

**é—®é¢˜**ï¼šæ— æ³•ä»HuggingFaceä¸‹è½½æ¨¡å‹

**è§£å†³**ï¼š
```bash
# æ–¹å¼1: ä½¿ç”¨é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# æ–¹å¼2: æ‰‹åŠ¨ä¸‹è½½
# è®¿é—®ï¼šhttps://hf-mirror.com/pyannote/speaker-diarization
# ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ°æœ¬åœ°ï¼Œç„¶åä½¿ç”¨æœ¬åœ°è·¯å¾„
```

### 4. å†…å­˜ä¸è¶³

**é—®é¢˜**ï¼š`CUDA out of memory`

**è§£å†³**ï¼š
```python
# å‡å°‘batch sizeæˆ–éŸ³é¢‘é•¿åº¦
# æˆ–è€…åˆ‡æ¢åˆ°CPUæ¨¡å¼
device = "cpu"
```

## ğŸ“ æœ€ä½³å®è·µ

### 1. éŸ³é¢‘é¢„å¤„ç†

```python
# è½¬æ¢ä¸ºWAVæ ¼å¼ï¼Œ16kHzï¼Œå•å£°é“
import librosa
import soundfile as sf

audio, sr = librosa.load("input.mp3", sr=16000, mono=True)
sf.write("output.wav", audio, 16000)
```

### 2. æ‰¹é‡å¤„ç†

```python
# å¯¹é•¿éŸ³é¢‘åˆ†æ®µå¤„ç†
def process_long_audio(audio_path, segment_duration=300):
    """
    åˆ†æ®µå¤„ç†é•¿éŸ³é¢‘
    segment_duration: æ¯æ®µæ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5åˆ†é’Ÿ
    """
    # åŠ è½½éŸ³é¢‘
    audio, sr = librosa.load(audio_path, sr=16000)
    total_duration = len(audio) / sr

    results = []
    for start in range(0, int(total_duration), segment_duration):
        end = min(start + segment_duration, total_duration)
        segment = audio[start*sr:end*sr]

        # å¤„ç†è¿™ä¸€æ®µ
        # ...

        results.append(segment_result)

    return results
```

### 3. ç»“æœç¼“å­˜

```python
# å¯¹ç›¸åŒéŸ³é¢‘ç¼“å­˜ç»“æœ
import hashlib
import json
from pathlib import Path

def get_audio_hash(audio_path):
    """è®¡ç®—éŸ³é¢‘æ–‡ä»¶hash"""
    with open(audio_path, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()

def cache_result(audio_path, result):
    """ç¼“å­˜ç»“æœ"""
    cache_dir = Path("cache")
    cache_dir.mkdir(exist_ok=True)

    audio_hash = get_audio_hash(audio_path)
    cache_file = cache_dir / f"{audio_hash}.json"

    with open(cache_file, 'w') as f:
        json.dump(result, f)

def get_cached_result(audio_path):
    """è·å–ç¼“å­˜ç»“æœ"""
    cache_dir = Path("cache")
    audio_hash = get_audio_hash(audio_path)
    cache_file = cache_dir / f"{audio_hash}.json"

    if cache_file.exists():
        with open(cache_file, 'r') as f:
            return json.load(f)

    return None
```

## ğŸ”— ç›¸å…³èµ„æº

- pyannote.audio GitHub: https://github.com/pyannote/pyannote-audio
- å®˜æ–¹æ–‡æ¡£: https://github.com/pyannote/pyannote-audio/tree/develop/tutorials
- HuggingFaceæ¨¡å‹: https://huggingface.co/pyannote
- PyTorchå®˜ç½‘: https://pytorch.org/

## ğŸ’¡ ä¸‹ä¸€æ­¥

å®‰è£…å®Œæˆåï¼š

1. âœ… è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯å®‰è£…
2. âœ… é…ç½®åç«¯ `.env` æ–‡ä»¶
3. âœ… å¯åŠ¨åç«¯æœåŠ¡
4. âœ… æµ‹è¯•APIæ¥å£

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** æŸ¥çœ‹ä¸»é¡¹ç›®æ–‡æ¡£æˆ–æissue
