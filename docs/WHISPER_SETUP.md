# Whisper è¯­éŸ³è¯†åˆ«é…ç½®æŒ‡å—ï¼ˆå…è´¹æ–¹æ¡ˆï¼‰

## ğŸ¯ ä¸ºä»€ä¹ˆé€‰æ‹©Whisperï¼Ÿ

- âœ… **å®Œå…¨å…è´¹** - OpenAIå¼€æºæ¨¡å‹
- âœ… **æœ¬åœ°è¿è¡Œ** - æ— éœ€APIå¯†é’¥
- âœ… **æ•ˆæœä¼˜ç§€** - æ”¯æŒå¤šè¯­è¨€ï¼Œå‡†ç¡®ç‡é«˜
- âœ… **æ— ä½¿ç”¨é™åˆ¶** - æƒ³ç”¨å¤šä¹…ç”¨å¤šä¹…
- âœ… **éšç§ä¿æŠ¤** - æ•°æ®ä¸å‡ºæœ¬åœ°

**ç¼ºç‚¹ï¼š**
- éœ€è¦è¾ƒå¥½çš„ç”µè„‘é…ç½®ï¼ˆæ¨èæœ‰GPUï¼‰
- é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼ˆ1-3GBï¼‰

---

## ğŸš€ å¿«é€Ÿå®‰è£…

### æ­¥éª¤1ï¼šå®‰è£…Pythonä¾èµ–

```bash
cd D:\Hennessy.uno\meeting-system-backend\python

# æ¿€æ´»ç¯å¢ƒ
pyannote-env\Scripts\activate

# å®‰è£…Whisper
pip install openai-whisper
```

### æ­¥éª¤2ï¼šæµ‹è¯•Whisper

```bash
# æµ‹è¯•å®‰è£…
python -c "import whisper; print('âœ… Whisperå®‰è£…æˆåŠŸ')"

# åŠ è½½æ¨¡å‹æµ‹è¯•ï¼ˆé¦–æ¬¡ä¼šä¸‹è½½ï¼‰
python -c "import whisper; model = whisper.load_model('base'); print('âœ… æ¨¡å‹åŠ è½½æˆåŠŸ')"
```

---

## ğŸ“ é›†æˆåˆ°é¡¹ç›®

### åˆ›å»ºWhisperæœåŠ¡

åˆ›å»ºæ–‡ä»¶ï¼š`python/whisper_service.py`

```python
#!/usr/bin/env python3
"""
Whisperè¯­éŸ³è¯†åˆ«æœåŠ¡
"""

import whisper
import sys
import json

def transcribe_audio(audio_path, language='zh'):
    """è½¬å½•éŸ³é¢‘æ–‡ä»¶"""
    try:
        # åŠ è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼štiny, base, small, medium, largeï¼‰
        # tiny: æœ€å¿«ï¼Œå‡†ç¡®ç‡è¾ƒä½
        # base: å¹³è¡¡é€‰æ‹© â­ æ¨è
        # small/medium: æ›´å‡†ç¡®ï¼Œæ›´æ…¢
        model = whisper.load_model("base")

        # è½¬å½•
        result = model.transcribe(
            audio_path,
            language=language,
            verbose=False
        )

        # è¿”å›ç»“æœ
        return {
            "success": True,
            "text": result["text"],
            "segments": [
                {
                    "start": seg["start"],
                    "end": seg["end"],
                    "text": seg["text"]
                }
                for seg in result["segments"]
            ],
            "language": result["language"]
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(json.dumps({"error": "è¯·æä¾›éŸ³é¢‘æ–‡ä»¶è·¯å¾„"}))
        sys.exit(1)

    audio_path = sys.argv[1]
    language = sys.argv[2] if len(sys.argv) > 2 else "zh"

    result = transcribe_audio(audio_path, language)
    print(json.dumps(result, ensure_ascii=False))
```

---

## ğŸ”§ Node.jsé›†æˆ

åˆ›å»ºWhisper Providerï¼š

æ–‡ä»¶ï¼š`src/services/providers/transcription/WhisperTranscription.ts`

```typescript
import { spawn } from 'child_process';
import path from 'path';
import { ITranscriptionProvider, TranscriptResult } from '../types';

export class WhisperTranscriptionProvider implements ITranscriptionProvider {
  readonly name = 'Whisper Speech Recognition';
  readonly type = 'whisper' as const;

  private pythonPath: string;

  constructor() {
    // Pythonç¯å¢ƒè·¯å¾„
    this.pythonPath = path.join(
      process.cwd(),
      'python',
      'pyannote-env',
      process.platform === 'win32' ? 'Scripts' : 'bin',
      'python'
    );
  }

  /**
   * è½¬å½•éŸ³é¢‘æ–‡ä»¶
   */
  async transcribeFile(audioFile: Buffer, options?: any): Promise<TranscriptResult> {
    try {
      // ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
      const tempPath = await this.saveTemp(audioFile);

      // è°ƒç”¨Pythonè„šæœ¬
      const result = await this.runWhisper(tempPath, options?.language || 'zh');

      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      await fs.unlink(tempPath);

      return {
        text: result.text,
        segments: result.segments.map((seg: any) => ({
          text: seg.text,
          startTime: seg.start,
          endTime: seg.end,
          confidence: 1.0 // Whisperä¸æä¾›ç½®ä¿¡åº¦
        })),
        language: result.language
      };

    } catch (error: any) {
      throw new Error(`Whisperè½¬å½•å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * è¿è¡ŒWhisper
   */
  private runWhisper(audioPath: string, language: string): Promise<any> {
    return new Promise((resolve, reject) => {
      const scriptPath = path.join(process.cwd(), 'python', 'whisper_service.py');

      const python = spawn(this.pythonPath, [scriptPath, audioPath, language]);

      let output = '';
      let errorOutput = '';

      python.stdout.on('data', (data) => {
        output += data.toString();
      });

      python.stderr.on('data', (data) => {
        errorOutput += data.toString();
      });

      python.on('close', (code) => {
        if (code !== 0) {
          reject(new Error(`Whisperæ‰§è¡Œå¤±è´¥: ${errorOutput}`));
          return;
        }

        try {
          const result = JSON.parse(output);

          if (!result.success) {
            reject(new Error(result.error));
            return;
          }

          resolve(result);
        } catch (error) {
          reject(new Error('è§£æWhisperç»“æœå¤±è´¥'));
        }
      });
    });
  }

  async healthCheck(): Promise<boolean> {
    try {
      const testResult = await this.runWhisper('test', 'zh');
      return true;
    } catch {
      return false;
    }
  }

  // å®æ—¶è½¬å½•æš‚ä¸æ”¯æŒ
  async startRealtime(): Promise<void> {
    throw new Error('Whisperä¸æ”¯æŒå®æ—¶è½¬å½•ï¼Œè¯·ä½¿ç”¨æ–‡ä»¶è½¬å½•');
  }

  async sendAudio(): Promise<void> {
    throw new Error('Whisperä¸æ”¯æŒå®æ—¶è½¬å½•');
  }

  async stopRealtime(): Promise<void> {
    throw new Error('Whisperä¸æ”¯æŒå®æ—¶è½¬å½•');
  }
}
```

---

## âš™ï¸ é…ç½®ä½¿ç”¨

ä¿®æ”¹ `.env` æ–‡ä»¶ï¼š

```env
# è½¬å½•æœåŠ¡é€‰æ‹©
TRANSCRIPTION_PROVIDER=whisper  # æˆ– iflytek

# Whisperé…ç½®
WHISPER_MODEL=base  # tiny, base, small, medium, large
WHISPER_LANGUAGE=zh
WHISPER_DEVICE=cpu  # æˆ– cudaï¼ˆå¦‚æœæœ‰GPUï¼‰
```

---

## ğŸ¯ æ¨¡å‹é€‰æ‹©

| æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | å‡†ç¡®ç‡ | æ¨èåœºæ™¯ |
|------|------|------|--------|----------|
| tiny | ~75MB | å¾ˆå¿« | è¾ƒä½ | å¿«é€Ÿæµ‹è¯• |
| **base** | ~150MB | å¿« | ä¸­ç­‰ | **å¼€å‘æ¨è** â­ |
| small | ~500MB | ä¸­ç­‰ | è‰¯å¥½ | ä¸€èˆ¬ä½¿ç”¨ |
| medium | ~1.5GB | æ…¢ | å¾ˆå¥½ | é«˜è´¨é‡éœ€æ±‚ |
| large | ~3GB | å¾ˆæ…¢ | æœ€å¥½ | ç”Ÿäº§ç¯å¢ƒ |

**å»ºè®®ï¼š** å¼€å‘æµ‹è¯•ç”¨ `base`ï¼Œç”Ÿäº§ç¯å¢ƒç”¨ `small` æˆ– `medium`

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### Whisper vs è®¯é£

| ç»´åº¦ | Whisper | è®¯é£ |
|------|---------|------|
| **è´¹ç”¨** | å®Œå…¨å…è´¹ âœ… | å…è´¹é¢åº¦åæ”¶è´¹ |
| **é€Ÿåº¦** | è¾ƒæ…¢ï¼ˆæœ¬åœ°è®¡ç®—ï¼‰ | å¿«ï¼ˆäº‘ç«¯ï¼‰ |
| **å‡†ç¡®ç‡** | ä¼˜ç§€ | ä¼˜ç§€ |
| **å®æ—¶æ€§** | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| **éšç§** | âœ… æœ¬åœ°å¤„ç† | ä¸Šä¼ åˆ°äº‘ç«¯ |
| **é…ç½®** | ç®€å• | éœ€è¦APIå¯†é’¥ |

**ç»“è®ºï¼š**
- **å¼€å‘æµ‹è¯•** â†’ ç”¨ Whisperï¼ˆå…è´¹ã€ç®€å•ï¼‰
- **å®æ—¶è½¬å½•** â†’ éœ€è¦è®¯é£æˆ–å…¶ä»–å®æ—¶API
- **ç”Ÿäº§ç¯å¢ƒ** â†’ æ ¹æ®éœ€æ±‚é€‰æ‹©

---

## ğŸ§ª æµ‹è¯•Whisper

```bash
# 1. æ¿€æ´»Pythonç¯å¢ƒ
cd python
pyannote-env\Scripts\activate

# 2. å®‰è£…Whisper
pip install openai-whisper

# 3. æµ‹è¯•è½¬å½•
python whisper_service.py test.wav zh
```

---

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### 1. GPUåŠ é€Ÿï¼ˆå¯é€‰ï¼‰

å¦‚æœæœ‰NVIDIA GPUï¼š

```bash
# å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# é…ç½®
WHISPER_DEVICE=cuda
```

é€Ÿåº¦æå‡ 10-20å€ï¼

### 2. æ¨¡å‹ç¼“å­˜

é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œåç»­ä½¿ç”¨ç¼“å­˜ï¼š

```python
# æ¨¡å‹ä¼šç¼“å­˜åœ¨ï¼š
# Windows: C:\Users\ç”¨æˆ·å\.cache\whisper\
# Linux/Mac: ~/.cache/whisper/
```

### 3. æ‰¹é‡å¤„ç†

å¯¹äºå¤šä¸ªæ–‡ä»¶ï¼Œå¯ä»¥é‡ç”¨æ¨¡å‹ï¼š

```python
model = whisper.load_model("base")  # åŠ è½½ä¸€æ¬¡

for audio_file in audio_files:
    result = model.transcribe(audio_file)
    # å¤„ç†ç»“æœ...
```

---

## â“ å¸¸è§é—®é¢˜

### Q: Whisperæ”¯æŒä¸­æ–‡å—ï¼Ÿ
**A:** å®Œå…¨æ”¯æŒï¼å‡†ç¡®ç‡å¾ˆé«˜ã€‚

### Q: éœ€è¦è”ç½‘å—ï¼Ÿ
**A:** é¦–æ¬¡ä¸‹è½½æ¨¡å‹éœ€è¦ï¼Œä¹‹åå¯ä»¥å®Œå…¨ç¦»çº¿ã€‚

### Q: å¯ä»¥å®æ—¶è½¬å½•å—ï¼Ÿ
**A:** Whisperè®¾è®¡ä¸ºæ‰¹é‡å¤„ç†ï¼Œä¸é€‚åˆå®æ—¶ã€‚å®æ—¶éœ€è¦ç”¨è®¯é£æˆ–å…¶ä»–æ–¹æ¡ˆã€‚

### Q: å†…å­˜å ç”¨å¤šå¤§ï¼Ÿ
**A:**
- tiny/base: 1-2GB
- small/medium: 2-4GB
- large: 4-8GB

---

## ğŸ¯ æ€»ç»“

**Whisperé€‚åˆï¼š**
- âœ… å½•åˆ¶å¥½çš„éŸ³é¢‘æ–‡ä»¶è½¬å½•
- âœ… ç¦»çº¿å¤„ç†åœºæ™¯
- âœ… ä¸æƒ³ä»˜è´¹çš„é¡¹ç›®
- âœ… é‡è§†éšç§çš„åœºæ™¯

**ä¸é€‚åˆï¼š**
- âŒ å®æ—¶è¯­éŸ³è½¬å½•
- âŒ é…ç½®è¾ƒä½çš„ç”µè„‘
- âŒ è¦æ±‚æå¿«å“åº”çš„åœºæ™¯

**æ¨èæ–¹æ¡ˆï¼š**
- **å¼€å‘/æµ‹è¯•** â†’ Whisperï¼ˆå…è´¹ã€ç®€å•ï¼‰
- **ç”Ÿäº§ç¯å¢ƒ** â†’ è®¯é£å…è´¹é¢åº¦ + Whisperæ··åˆ
- **å®æ—¶åœºæ™¯** â†’ å¿…é¡»ç”¨è®¯é£æˆ–ç±»ä¼¼å®æ—¶API

---

**ä¸‹ä¸€æ­¥ï¼š** è¿è¡Œ `pip install openai-whisper` å¼€å§‹ä½¿ç”¨ï¼
